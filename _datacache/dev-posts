[{"2020-6-12":"1"},["2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24"],{"type_of":"25","id":293929,"title":"26","description":"27","published":true,"published_at":"28","slug":"29","path":"30","url":"31","comments_count":6,"public_reactions_count":14,"page_views_count":151,"published_timestamp":"32","body_markdown":"33","positive_reactions_count":14,"cover_image":null,"tag_list":"34","canonical_url":"31","user":"35","flare_tag":"36"},{"type_of":"25","id":285045,"title":"37","description":"38","published":true,"published_at":"39","slug":"40","path":"41","url":"42","comments_count":2,"public_reactions_count":21,"page_views_count":605,"published_timestamp":"43","body_markdown":"44","positive_reactions_count":21,"cover_image":null,"tag_list":"45","canonical_url":"42","user":"46"},{"type_of":"25","id":284650,"title":"47","description":"47","published":true,"published_at":"48","slug":"49","path":"50","url":"51","comments_count":0,"public_reactions_count":7,"page_views_count":0,"published_timestamp":"52","body_markdown":"53","positive_reactions_count":7,"cover_image":null,"tag_list":"54","canonical_url":"51","user":"55"},{"type_of":"25","id":256229,"title":"56","description":"57","published":true,"published_at":"58","slug":"59","path":"60","url":"61","comments_count":15,"public_reactions_count":9,"page_views_count":88,"published_timestamp":"62","body_markdown":"63","positive_reactions_count":9,"cover_image":null,"tag_list":"64","canonical_url":"61","user":"65","flare_tag":"66"},{"type_of":"25","id":248182,"title":"67","description":"68","published":true,"published_at":"69","slug":"70","path":"71","url":"72","comments_count":0,"public_reactions_count":19,"page_views_count":226,"published_timestamp":"73","body_markdown":"74","positive_reactions_count":19,"cover_image":null,"tag_list":"75","canonical_url":"72","user":"76"},{"type_of":"25","id":214991,"title":"77","description":"78","published":true,"published_at":"79","slug":"80","path":"81","url":"82","comments_count":0,"public_reactions_count":7,"page_views_count":102,"published_timestamp":"83","body_markdown":"84","positive_reactions_count":7,"cover_image":"85","tag_list":"86","canonical_url":"82","user":"87"},{"type_of":"25","id":214252,"title":"88","description":"89","published":true,"published_at":"90","slug":"91","path":"92","url":"93","comments_count":0,"public_reactions_count":13,"page_views_count":249,"published_timestamp":"94","body_markdown":"95","positive_reactions_count":13,"cover_image":"96","tag_list":"97","canonical_url":"93","user":"98"},{"type_of":"25","id":159403,"title":"99","description":"100","published":true,"published_at":"101","slug":"102","path":"103","url":"104","comments_count":15,"public_reactions_count":78,"page_views_count":1660,"published_timestamp":"105","body_markdown":"106","positive_reactions_count":78,"cover_image":"107","tag_list":"108","canonical_url":"104","user":"109"},{"type_of":"25","id":125734,"title":"110","description":"111","published":true,"published_at":"112","slug":"113","path":"114","url":"115","comments_count":7,"public_reactions_count":8,"page_views_count":422,"published_timestamp":"116","body_markdown":"117","positive_reactions_count":8,"cover_image":null,"tag_list":"118","canonical_url":"115","user":"119","flare_tag":"120"},{"type_of":"25","id":94003,"title":"121","description":"122","published":true,"published_at":"123","slug":"124","path":"125","url":"126","comments_count":5,"public_reactions_count":5,"page_views_count":639,"published_timestamp":"127","body_markdown":"128","positive_reactions_count":5,"cover_image":null,"tag_list":"129","canonical_url":"126","user":"130","flare_tag":"131"},{"type_of":"25","id":48323,"title":"132","description":"133","published":true,"published_at":"134","slug":"135","path":"136","url":"137","comments_count":3,"public_reactions_count":4,"page_views_count":53,"published_timestamp":"138","body_markdown":"139","positive_reactions_count":4,"cover_image":null,"tag_list":"140","canonical_url":"137","user":"141","organization":"142"},{"type_of":"25","id":87288,"title":"143","description":"144","published":true,"published_at":"145","slug":"146","path":"147","url":"148","comments_count":13,"public_reactions_count":14,"page_views_count":772,"published_timestamp":"149","body_markdown":"150","positive_reactions_count":14,"cover_image":null,"tag_list":"151","canonical_url":"148","user":"152"},{"type_of":"25","id":61794,"title":"153","description":"154","published":true,"published_at":"155","slug":"156","path":"157","url":"158","comments_count":0,"public_reactions_count":34,"page_views_count":643,"published_timestamp":"159","body_markdown":"160","positive_reactions_count":34,"cover_image":null,"tag_list":"161","canonical_url":"158","user":"162"},{"type_of":"25","id":44658,"title":"163","description":"164","published":true,"published_at":"165","slug":"166","path":"167","url":"168","comments_count":3,"public_reactions_count":13,"page_views_count":425,"published_timestamp":"169","body_markdown":"170","positive_reactions_count":13,"cover_image":null,"tag_list":"171","canonical_url":"168","user":"172"},{"type_of":"25","id":42261,"title":"173","description":"174","published":true,"published_at":"175","slug":"176","path":"177","url":"178","comments_count":0,"public_reactions_count":30,"page_views_count":2910,"published_timestamp":"179","body_markdown":"180","positive_reactions_count":30,"cover_image":null,"tag_list":"181","canonical_url":"178","user":"182"},{"type_of":"25","id":41592,"title":"183","description":"184","published":true,"published_at":"185","slug":"186","path":"187","url":"188","comments_count":2,"public_reactions_count":28,"page_views_count":1278,"published_timestamp":"189","body_markdown":"190","positive_reactions_count":28,"cover_image":null,"tag_list":"191","canonical_url":"188","user":"192"},{"type_of":"25","id":41252,"title":"193","description":"194","published":true,"published_at":"195","slug":"196","path":"197","url":"198","comments_count":11,"public_reactions_count":67,"page_views_count":3643,"published_timestamp":"199","body_markdown":"200","positive_reactions_count":67,"cover_image":null,"tag_list":"201","canonical_url":"198","user":"202"},{"type_of":"25","id":41317,"title":"203","description":"204","published":true,"published_at":"205","slug":"206","path":"207","url":"208","comments_count":0,"public_reactions_count":40,"page_views_count":1289,"published_timestamp":"209","body_markdown":"210","positive_reactions_count":40,"cover_image":null,"tag_list":"211","canonical_url":"208","user":"212"},{"type_of":"25","id":32976,"title":"213","description":"214","published":true,"published_at":"215","slug":"216","path":"217","url":"218","comments_count":0,"public_reactions_count":15,"page_views_count":252,"published_timestamp":"219","body_markdown":"220","positive_reactions_count":15,"cover_image":null,"tag_list":"221","canonical_url":"218","user":"222"},{"type_of":"25","id":30788,"title":"223","description":"224","published":true,"published_at":"225","slug":"226","path":"227","url":"228","comments_count":2,"public_reactions_count":68,"page_views_count":3734,"published_timestamp":"229","body_markdown":"230","positive_reactions_count":68,"cover_image":"231","tag_list":"232","canonical_url":"228","user":"233"},{"type_of":"25","id":17968,"title":"234","description":"235","published":true,"published_at":"236","slug":"237","path":"238","url":"239","comments_count":7,"public_reactions_count":11,"page_views_count":492,"published_timestamp":"240","body_markdown":"241","positive_reactions_count":11,"cover_image":"242","tag_list":"243","canonical_url":"239","user":"244"},{"type_of":"25","id":8505,"title":"245","description":"246","published":true,"published_at":"247","slug":"248","path":"249","url":"250","comments_count":3,"public_reactions_count":15,"page_views_count":1737,"published_timestamp":"251","body_markdown":"252","positive_reactions_count":15,"cover_image":"253","tag_list":"254","canonical_url":"250","user":"255"},{"type_of":"25","id":5622,"title":"256","description":"257","published":true,"published_at":"258","slug":"259","path":"260","url":"261","comments_count":1,"public_reactions_count":8,"page_views_count":0,"published_timestamp":"262","body_markdown":"263","positive_reactions_count":8,"cover_image":null,"tag_list":"264","canonical_url":"261","user":"265"},"article","Blog post writing app demo","Hello Devs üëãüèº  I want to showcase an app I've been working on for the past few weeks. It aims to solv...","2020-03-28T18:08:52.458Z","blog-post-writing-app-demo-83k","/david_ojeda/blog-post-writing-app-demo-83k","https://dev.to/david_ojeda/blog-post-writing-app-demo-83k","2020-03-28T18:08:52Z","Hello Devs üëãüèº\n\n\nI want to showcase an app I've been working on for the past few weeks. It aims to solve the pains I have when writing my blog posts:\n\n- I can't remember the Markdown syntax to create a link or image. Is it () or [] first? ü§î\n- Different post destinations use different formats; HTML, Markdown, etc.\n- I don't like to use apps that don't respect my privacy, e.g., Grammarly.\n\nI made a video tour of my work so far; bare with me please since I'm terrible at video üòÖ\n\n{% youtube NICjX4w85jg %}\n\n# A brief summary:\n\nA **blog post writing app** to **write your content once**, and **publish it anywhere** you want.\n\nMain features:\n - No specific syntax required, write with common text processor tools üëåüèº.\n - Grammar and insensitive checks out of the box; nothing leaves your browser üñç.\n - Automatic browser storage to avoid losing your content üîÑ.\n - Easy and intuitive image uploads üå†.\n - Post **directly to DEV.to as a draft** üò±.\n - Export as Markdown or HTML ‚¨áÔ∏è.\n\nI'd like for this app to also help me follow a template or style, which I'm still trying to find. I'll see how to add that in the near future.\n\nAny feedback is really appreciated! üôèüèº And if you want to try it out, let me know! \n\n**UPDATE: My app has a name! It's called Nina, like my dog üêï.**\n\nThanks a lot üíô\n",["266","267"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},{"name":"266","bg_color_hex":"275","text_color_hex":"276"},"AWS S3: The Basics","This post describes what Amazon Simple Storage Service (S3) is, how it works at a high level, and why you might need it.","2020-03-26T18:56:39.771Z","aws-s3-the-basics-1e4g","/david_ojeda/aws-s3-the-basics-1e4g","https://dev.to/david_ojeda/aws-s3-the-basics-1e4g","2020-03-26T18:56:39Z","---\ntitle: AWS S3: The Basics\npublished: true\ndescription: This post describes what Amazon Simple Storage Service (S3) is, how it works at a high level, and why you might need it.\ntags: aws, s3\nseries: AWS S3\n---\n\n*Disclaimer: This is the second revision of a [post I did before about this same topic](https://dev.to/david_ojeda/aws-s3-pt-1---the-basics-55bp). I feel that I could improve it, and now really commit to expanding on it in a series.*\n\n***\n\nStoring and downloading files and data is a common activity for most applications. Where do you centralize this information? Amazon **Simple Storage Service (S3)** is a great option!¬†  \n  \nIn this post we'll learn the following:  \n  \n*   What Amazon S3 is.\n*   How it works at a high level.\n*   Why you might need it.\n\nLet's get to it!\n\n# What is S3?\n\nS3 is the object storage solution of **Amazon Web Services** (**AWS**) to reliably store and retrieve data. Some concrete examples of things you can store include:  \n  \n*   Your entire static web site:\n    *   _HTML, CSS, JS_\n*   Assets for your apps for later retrieval through a Content Delivery Network:\n    *   _Images, videos_\n*   Build files to keep a history and implement rollbacks:\n    *   _.zip, .war_\n*   Data exports for your customers:\n    *   _CSV, XLS, JSON_\n*   Logs for later analytics processing:\n    *   _.log, .txt_\n\n  \nS3 is also one of the most used services of AWS since it provides integrations with many of its other offerings.¬†\n\n# How is data stored?\n\nS3 stores our data as **objects** inside **buckets**. You can see **buckets** as a top-level directory on your drive, followed by a **key**, which is the path to our **object**.¬†\n\n![S3 directory structure](https://d1f6qu3m1nxo77.cloudfront.net/tmp/2020-03-10/1583820501981-image.png)\n  \nOnce we have objects in our buckets, we can retrieve them in many different ways. The following are the most common:¬†\n\n*   From the AWS console.\n*   With the AWS SDKs.\n*   Through the REST API.\n*   With a signed URL.\n  \nWe'll talk about each one in a different post.¬†  \n  \nNow, in terms of security, you probably don't want all your files to be publicly available. Data leaks are common, and it happens because customers leave their S3 buckets public.  \n  \nS3 allows us to create policies and rules to explicitly define who has access to each bucket and/or object in our account. The available options to restrict/allow access are overwhelming and often confusing, even to experienced people, that's why you see many data leaks.  \n  \nI will not dive into the permissions options in this post. Right now, our takeaway is that you can, somehow, restrict access to your data.  \n  \n# S3 Consistency model\n\nA [consistency model](https://en.wikipedia.org/wiki/Consistency_model) is a set of rules that, if followed, guarantee consistent results of reading, writing and/or updating your data.  \n  \nS3's consistency model is called **Read-after-Write** consistency. For example, if you issue a PUT request to create an object on a bucket, the next GET request will **ALWAYS** have the desired object.  \n  \nHowever, if you try to issue requests in the following order, immediately one after the other:  \n  \n1.  GET, when the object doesn't exist\n2.  PUT¬†\n3.  GET¬†\n\nYou _MIGHT_ not found the desired object. The consistency model when issuing the request in this order is now called **eventual** consistency. In other words:  \n  \n**Read-after-Write consistency**:  \n  \n\n*   PUT /my-bucket/photo.png -> 200 _ok_\n*   GET /my-bucket/photo.png -> 200 _ok_\n\n  \n**Eventual consistency**:  \n  \n\n*   GET /my-bucket/photo.png -> 404 _not found_\n*   PUT /my-bucket/photo.png -> 200 _ok_\n*   GET /my-bucket/photo.png -> 404 _not found_\n\n  \nSome changes made to your S3 buckets need time to propagate and replicate through AWS servers. For example, when you delete an object you also get eventual consistency; you _MIGHT_ see an object listed on your bucket even though you already deleted it a couple of seconds ago.¬†\n\n\n# Why do I need S3?\n\n  \nIf you need to store files or data that doesn't fit on a database, and you need them to be available from the internet, you probably need a solution like S3.  \n  \nWhy S3 specifically? Here are some reasons:  \n  \n\n*   Virtually unlimited storage space.\n*   Stored objects availability is 99.99% by default (We'll talk more about this in another post).\n*   Objects' tight access restrictions depending on security requirements.\n*   Pay for what you use: space occupied and requests.\n*   Integration with most of the other AWS services.\n*   Low entry barrier.\n\n  \nS3 has many more interesting features. The ones mentioned before are the ones I consider most important.  \n  \n\n# Wrap up\n\n  \nWhenever you are evaluating a storage solution to use, S3 will probably be on the top three. It's a highly secure, available, and performant service that can solve most of your storage problems.  \n  \nIn the next post we'll create our first buckets and objects with S3. Also, we'll cover how to properly secure them üîê. Stay tuned!  \n  \nThanks for reading me üíú.",["277","278"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"Enable \"Ignore load balancer 4xx errors\" health rule on AWS Elastic Beanstalk using .ebextensions","2020-03-20T00:50:17.803Z","enable-ignore-load-balancer-4xx-errors-health-rule-on-aws-elastic-beanstalk-using-ebextensions-4ac9","/david_ojeda/enable-ignore-load-balancer-4xx-errors-health-rule-on-aws-elastic-beanstalk-using-ebextensions-4ac9","https://dev.to/david_ojeda/enable-ignore-load-balancer-4xx-errors-health-rule-on-aws-elastic-beanstalk-using-ebextensions-4ac9","2020-03-20T00:50:17Z","---\ntitle: Enable \"Ignore load balancer 4xx errors\" health rule on AWS Elastic Beanstalk using .ebextensions\npublished: true\ndescription: Enable \"Ignore load balancer 4xx errors\" health rule on AWS Elastic Beanstalk using .ebextensions\ntags: aws, ElasticBeanstalk\n---\n\nIf you are an **Elastic Beanstalk (EB)** user, you are probably aware of a frequently [requested feature that was released on July 25, 2018](https://aws.amazon.com/releasenotes/release-aws-elastic-beanstalk-support-for-enhanced-health-rule-customization-on-july-25-2018/?tag=releasenotes%23keywords%23aws-elastic-beanstalk): To ignore application 4xx errors when determining your environment's health. It's was a new EB health rule that ignores 400-499 HTTP status codes when alerting if your environment instances are having trouble üè•.  \n  \nIt is common for applications to receive many 4xx errors, for example, due to:  \n  \n\n*   Client's API integrations using invalid credentials.\n*   Client-side test tools.\n*   Broken links that create 404 responses.\n\n  \nI started to use this feature since the moment it was released.  \n  \n\nToday I logged in into my EB console and switched the design to the latest version of the console. Everything okay. Then, as I was exploring the new console, I noticed a new configuration that was not previously available: **To ignore load balancer 4xx errors**.  \n  \nIn this post, I will show you, through a story, how to enable this feature using [_.ebextensions_](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/ebextensions.html), because, infrastructure-as-code, you know ü§ì. The funny part, I can't seem to find the documentation anywhere on AWS. Never happened before, right? üôÉ.¬†  \n  \nFollow along!  \n  \n\n# Digging through the docs üóÇ\n\n  \nThe first thing I do when trying to configure this new feature is: go to the [docs page where the almost identical feature is documented](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/health-enhanced-rules.html), that is, the ignore **application** 4xx errors. I found that is the same page as it was before, with no extra information about a load balancer health rule. Citing the docs:  \n  \n\n> Currently, this is the only available enhanced heath rule customization. You can't configure enhanced health to ignore HTTP errors returned by an environment's load balancer, or other HTTP errors in addition to 4xx.\n\n  \nLiars! Just kidding üòù¬†  \n  \nWithout luck on this doc page, I proceeded to look somewhere else:  \n  \n\n*   Went through the [EB release notes](https://aws.amazon.com/releasenotes/?tag=releasenotes%23keywords%23aws-elastic-beanstalk) to see if I missed the announcement. No luck.\n*   Went to the [EB public roadmap](https://github.com/aws/elastic-beanstalk-roadmap/projects/1) and found nothing there either.\n*   [Asked on Twitter](https://twitter.com/DavidOjedaL/status/1240705686343798784), but since no one follows all I got was a response from AWS support to look at their forum. Go [follow me](https://twitter.com/DavidOjedaL) on Twitter! üëÄ.\n*   Went to the EB forums and only found people asking how to work around the fact that there was no feature to ignore load balancer 4xx errors ü§¶üèª‚Äç‚ôÇÔ∏è.\n*   Asked a [question in StackOverflow](https://stackoverflow.com/questions/60764891/how-to-enable-aws-elastic-beanstalk-health-rule-ignore-load-balancer-4xx-throu?noredirect=1#comment107510426_60764891) and got a comment saying that I should create a support ticket.\n\n  \n\n# What next‚ùì\n\n  \nI had already searched through a lot of docs without any progress. I posted the question on Twitter and StackOverflow, and I wasn't expecting any response soon. I thought about trying to guess the new field names and do a try-error session.  \n  \nMy current configuration document looks like this:  \n  \n\n```json\n{\n  \"Rules\": {\n    \"Environment\": {\n      \"Application\": {\n        \"ApplicationRequests4xx\": {\n          \"Enabled\": false\n        }\n      }\n    }\n  },\n  \"Version\": 1\n}\n```\n\n  \nIf I were the software developer that created this feature, how would I call the new field? Some options:  \n  \n\n*   LoadBalancerRequests4xx\n*   ALBRequests4xx\n*   ELBRequests4xx\n\n  \nBut, should they be nested under \"Application\" or should it be another high-level field? By this time I was already hungry, so I went to cook and eat üë®üèª‚Äçüç≥üç≤  \n  \n\n# **Enlightenment**! üîÆ\n\n  \n**Taking a break helps**, you should consider it in your daily routine. Back to the topic...¬†  \n  \nI realized that even though I can't find a way to configure this feature through code, I can do it directly in the console. This would only be temporary because the environments re-create themselves on each deploy- any new environment would have this feature disabled.  \n  \nAnd here is where I got an ideaüí° What if I:  \n  \n\n1.  Enable the feature on the console.\n2.  Save the environment configuration as an [EB Saved Configuration](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-savedconfig.html).\n3.  Retrieve it with the EB CLI to see how the field is called at an API level.\n\n  \nThat's exactly what I did. Once the configuration was saved, I retrieved it:  \n  \n\n```bash\n$ eb config get NAME_OF_MY_CONFIGURATION\n```\n\n  \nand üí•, the configuration showed itself:  \n  \n\n```json\n{\n  \"Rules\": {\n    \"Environment\": {\n      \"ELB\": {\n        \"ELBRequests4xx\": {\n          \"Enabled\": false\n        }\n      },\n      \"Application\": {\n        \"ApplicationRequests4xx\": {\n          \"Enabled\": false\n        }\n      }\n    }\n  }\n}\n```\n\n  \nThere was a high-level field called \"_ELB\"_, and a property \"_ELBRequests4XX_\"; I was not that erred üë®üèª‚Äçüíª.  \n  \nI added those new fields to my .config file on the _.ebextensions_ folder and everything worked as expected üëèüèº Here is the final .config file I used:  \n  \n\n```yaml\noption_settings:\n  - namespace: aws:elasticbeanstalk:healthreporting:system\n    option_name: ConfigDocument\n    value: {\n\"Rules\": {\n  \"Environment\": {\n    \"ELB\": {\n      \"ELBRequests4xx\": {\n        \"Enabled\": false\n      }\n    },\n    \"Application\": {\n      \"ApplicationRequests4xx\": {\n        \"Enabled\": false\n      }\n    }\n  }\n},\n\"Version\": 1\n}\n```\n\n  \n\n# Wrap up üîÑ\n\n  \nI can't imagine how complex is to add a feature to a system as big as AWS while maintaining all the docs updated. I don't blame them.  \n  \nNonetheless, we figured out at the end üôåüèº. In short, to configure your EB environments to ignore load balancer 4xx errors, you need to add the previous .config file to your .ebextensions folder and deploy a new version.  \n  \nMaybe the docs are updated by the time you read this, and the story will not be that fun üôÉ Anyhow, it was a blast to write.  \n  \nI hope you enjoyed it. Thanks for reading me üíô",["277","279"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"What are you learning or planning to learn next? üìö","Are you struggling with something specific?","2020-02-05T23:14:44.284Z","what-are-you-learning-or-planning-to-learn-next-499d","/david_ojeda/what-are-you-learning-or-planning-to-learn-next-499d","https://dev.to/david_ojeda/what-are-you-learning-or-planning-to-learn-next-499d","2020-02-05T23:14:44Z","Are you struggling with something specific? ",["280"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},{"name":"280","bg_color_hex":"281","text_color_hex":"282"},"Copy to clipboard button with Stimulus 2.0 (Beta)","Stimulus is a JavaScript framework developed by a team at Basecamp, and it aims to augment your exist...","2020-01-28T00:46:41.565Z","copy-to-clipboard-button-with-stimulus-2-0-beta-1nll","/david_ojeda/copy-to-clipboard-button-with-stimulus-2-0-beta-1nll","https://dev.to/david_ojeda/copy-to-clipboard-button-with-stimulus-2-0-beta-1nll","2020-01-28T00:46:41Z","[**Stimulus**](https://stimulusjs.org/handbook/introduction) is a JavaScript framework developed by a team at [Basecamp](https://basecamp.com/), and it aims to augment your existing HTML so things work without too much \"connecting\" code.\n\nContrary to other frameworks, Stimulus doesn't take over your front-end, so you can add it without too much hassle to your already running app.  \n\n**Its documentation is very clear and digestible**. Included in its handbook is an [example of building a clipboard functionality](https://stimulusjs.org/handbook/building-something-real), which I recommend you go through if you are trying Stimulus for the first time.\n\nRight now we are **replicating** that functionality and adding a couple more things **using a development build** specified in this Pull Request (PR)\n\n{% github https://github.com/stimulusjs/stimulus/pull/202 %}\n\nIt **includes new APIs that will be released with version 2.0** of the framework, so they are not yet available with the current stable production release.\n\n# What are we building?\n\nA one-time password \"copy to clipboard\" button what wraps the DOM Clipboard API.\n\nYou can access the final working version on [Glitch](https://glitch.com/edit/#!/trapezoidal-seer):\n\n{% glitch trapezoidal-seer %}\n\n# Starting off\n\nFirst, we are creating our base HTML where the one-time password will be and the actual button to copy it:\n\n```html\n<div>\n  <label>\n    One-time password:\n    <input type=\"text\" value=\"fbbb5593-1885-4164-afbe-aba1b87ea748\" readonly=\"readonly\">\n  </label>\n\n  <button>\n    Copy to clipboard\n  </button>\n</div>\n```\n\n![Text input with \"copy to clipboard button\" rendered HTML](https://thepracticaldev.s3.amazonaws.com/i/bu8kact7stjzee0flm5a.png)\n\n\nThis doesn't do anything by itself; we need to add our Stimulus controller.\n\n# The controller definition\n\nIn Stimulus, **a controller is a JavaScript object that automatically connects to DOM elements that have certain identifiers**.\n\nLet's define our clipboard controller. The main thing it needs to do? Grab the text on the input field and copy it to the clipboard:\n\n```javascript\n\n(() => {\n  const application = Stimulus.Application.start();\n\n  application.register(\"clipboard\", class extends Stimulus.Controller {\n    // We'll get to this below\n    static get targets() {\n      return ['source']\n    }\n\n    copy() {\n      // Here goes the copy logic \n    }\n  });\n\n})();\n```\n\nNow, this is a valid controller that doesn't do anything because it's not connected to any DOM element yet.\n\n# Connecting the controller\n\nAdding a `data-controller` attribute to our `div` will enable the connection:\n\n```html\n<div data-controller=\"clipboard\">\n\n[...]\n```\n\nRemember the `static get targets()` from above? That allows us to **access DOM elements as properties in the controller**. \n\nSince there is already a `source` target, we can now access any DOM element with the attribute `data-clipboard-target=\"source\"`:\n\n```html\n[...]\n\n<input data-clipboard-target=\"source\" type=\"text\" value=\"fbbb5593-1885-4164-afbe-aba1b87ea748\" readonly=\"readonly\">\n\n[...]\n```\n\nAlso, we need the button to actually do something. We can link the \"Copy to clipboard\" button to the `copy` action in our controller with another identifier: `data-action=\"clipboard#copy\"`. The HTML now looks like this:\n\n```html\n<div data-controller=\"clipboard\">\n  <label>\n    One-time password:\n    <input data-clipboard-target=\"source\" type=\"text\" value=\"fbbb5593-1885-4164-afbe-aba1b87ea748\" readonly=\"readonly\">\n  </label>\n\n  <button data-action=\"clipboard#copy\">\n    Copy to clipboard\n  </button>\n</div>\n```\n\nOur controller is now automatically connected to the DOM, and clicking the copy button will invoke the `copy` function; let's proceed to write it.\n\n# The copy function\n\nThis function is essentially a **wrapper of the DOM Clipboard API**. The logic goes like this:\n\n```javascript\n[...]\n\ncopy() {\n  this.sourceTarget.select();\n  document.execCommand('copy');\n}\n\n[...]\n```\n\nWe take the `source` target we defined earlier, our text input that is, select its content, and use the Clipboard API to copy it to our clipboard.\n\nAt this point, **the functionality is practically done!** You can press the button and the one-time password is now available for you on your clipboard.\n\n# Moving further\n\nThe copy button works now, but we can go further. **What if the browser doesn't support the Clipboard API or JavaScript is disabled?**\n\nIf that's the case, we are going to hide the copy button entirely.\n\n# Checking API availability\n\nWe can check if the `copy` command is available to us by doing this:\n\n```javascript\ndocument.queryCommandSupported(\"copy\")\n```\n\nOne of the best places to check this is when the Stimulus controller connects to the DOM. Stimulus gives us some nice **lifecycle callbacks** so we can know when this happens. \n\nWe can create a `connect` function on our controller and it will be invoked whenever this controller connects to the DOM:\n\n```javascript\n[...]\n\nconnect() {\n  if (document.queryCommandSupported(\"copy\")) \n    // Proceed normally\n  }\n} \n\n[...]\n```\n\nOne way to hide/show the copy button depending on the API availability is to initially load the page with the button hidden, and then displaying it if the API is available. \n\nTo achieve this we can rely on CSS:\n\n```css\n.clipboard-button {\n  display: none;\n}\n\n/* Match all elements with .clipboard-button class inside the element with .clipboard--supported class */\n.clipboard--supported .clipboard-button {\n  display: initial;\n}\n```\n\nOur button is now hidden from the beginning, and will only be visible when we add the `.clipboard--supported` class to our `div`.\n\nTo do it, we modify the connect lifecycle callback. \n\nHere is where we can start to see major differences from this latest development version. With the actual production version you would need to specify the CSS class in the controller, effectively doing this:\n\n```javascript\n[...]\n\nconnect() {\n  if (document.queryCommandSupported(\"copy\")) \n    this.element.classList.add('clipboard--supported');\n  }\n} \n\n[...]\n```\n\n**There is a new, better way to achieve it.**\n\n# Classes API\n\nNow, **CSS classes can be actual properties of the controller**. To do so, we need to add some identifiers to our HTML and add a new array to our controller:\n\n```html\n<div data-controller=\"clipboard\" data-clipboard-supported-class=\"clipboard--supported\" class=\"clipboard\">\n\n[...]\n```\n\n```javascript\n[...]\n\napplication.register(\"clipboard\", class extends Stimulus.Controller {\n\n[...]\n\n  static classes = ['supported']\n\n  connect() {\n    if (document.queryCommandSupported(\"copy\")) \n      this.element.classList.add(this.supportedClass);\n    }\n  } \n[...]\n```\n\nGreat! Now we can access our supported class string from our controller with `this.supportedClass`. **This will help keep things loosely coupled.**\n\nThe clipboard real-life example from Stimulus' handbook ends here. Now, to show the other newest additions and use the *Classes API* once more, we're adding the following functionality:\n\n- A new style to the \"Copy to clipboard\" button once it has been clicked\n- A refresh interval for the one-time password. This will generate a new password every 2.5 seconds\n- A data attribute to keep track of how many times the password has been generated\n\n# Values API\n\nThis, along with the *Classes API*, is one of the new additions to Stimulus. Before this API you would need to add arbitrary values to your controller with the Data Map API, that is, adding `data-[identifier]-[variable-name]` to your DOM element, and then parsing that value in your controller. \n\nThis created boilerplate such as getters and setters with calls to `parseFloat()`, `parseInt()`, `JSON.stringify()`, etc. This is how it will work with the *Values API*:\n\n```html\n<div data-controller=\"clipboard\" data-clipboard-supporte-class=\"clipboard--supported\" data-clipboard-refresh-interval-value=\"2500\" class=\"clipboard\">\n\n[...]\n```\n\n```javascript\n[...]\n\napplication.register(\"clipboard\", class extends Stimulus.Controller {\n\n[...]\n\n  static values = {\n    refreshInterval: Number\n  }\n\n  connect() {\n    if (document.queryCommandSupported(\"copy\")) \n      this.element.classList.add(this.supportedClass);\n    }\n    // Access refreshInterval value directly\n    this.refreshIntervalValue; // 2500\n  } \n[...]\n```\n\n**Accessing your controller values is now cleaner since you don't need to write your getters and setters, nor do you need to parse from String to the type you need.**\n\nMoving forward, let's write the one-time password refresh.\n\n# Implementing password generation\n\nWe're going to define a new function to create a new random password. [I grabbed this random UUID generator snippet from the internet](https://www.arungudelli.com/tutorial/javascript/how-to-create-uuid-guid-in-javascript-with-examples/):\n\n```javascript\n([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>\n                (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16));\n```\n\nAdding it to our Stimulus controller:\n\n```javascript\n  connect() {\n    if (document.queryCommandSupported(\"copy\")) \n      this.element.classList.add(this.supportedClass);\n    }\n    if(this.hasRefreshIntervalValue) {\n          setInterval(() => this.generateNewPassword(), this.refreshIntervalValue)  \n    } \n  } \n\n  // copy function\n\n  generateNewPassword() {\n    this.sourceTarget.value = ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>\n                (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16));\n  }\n[...]\n```\n\nWe use `setInterval` to refresh our password text field each 2500ms since that's the value we defined in the DOM. \n\n**Our refresh feature is now working!** Some things still missing:\n- Add new style when copy button is clicked\n- Keep track of how many times a password is generated\n\nGiving all we have learned so far, this is what's need to be done:\n- Add a new CSS class to the stylesheet, DOM element, and controller\n- Add this new class when the button is clicked, and remove it when the password is refreshed\n- Add to a counter when the password refreshes\n\nThis is how it will look at the end:\n\n```css \n/* CSS */\n\n.clipboard-button {\n display: none;\n}\n\n.clipboard--supported .clipboard-button {\n  display: initial;\n}\n      \n.clipboard--success .clipboard-button {\n  background-color: palegreen;\n}\n```\n\n```html\n<!-- HTML -->\n\n<div data-controller=\"clipboard\" \n     data-clipboard-refresh-interval-value=\"2500\"\n     data-clipboard-supported-class=\"clipboard--supported\" \n     data-clipboard-success-class=\"clipboard--success\"      \n     data-clipboard-times-generated-value=\"1\" \n     >\n      \n      <label>\n        One-time password: <input data-clipboard-target=\"source\" type=\"text\" value=\"fbbb5593-1885-4164-afbe-aba1b87ea748\" readonly=\"readonly\">\n      </label>\n      \n      <button data-action=\"clipboard#copy\"               \n              class=\"clipboard-button\" >\n        Copy to Clipboard\n      </button>\n            \n    </div>\n```\n\n```javascript\n // JavaScript\n\n (() => {\n    const application = Stimulus.Application.start()\n\n    application.register(\"clipboard\", class extends Stimulus.Controller {\n\n      static get targets() {\n        return ['source']\n      }\n\n      static values = {              \n        refreshInterval: Number,\n        timesGenerated: Number\n      }\n\n      static classes = ['supported', 'success'];\n\n      connect() {                 \n        if (document.queryCommandSupported(\"copy\")) {\n          this.element.classList.add(this.supportedClass);                \n        }                            \n        if(this.hasRefreshIntervalValue) {\n          setInterval(() => this.generateNewPassword(), this.refreshIntervalValue)  \n        } \n      }\n\n\n      copy() {              \n        this.sourceTarget.select();\n        document.execCommand('copy');\n        this.element.classList.add(this.successClass);\n      }\n\n      generateNewPassword() {              \n        this.sourceTarget.value = ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>\n          (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16));     \n        this.element.classList.remove(this.successClass);\n        this.timesGeneratedValue++;\n      }                  \n\n      // NEW! Read about it below\n      timesGeneratedValueChanged() {              \n        if(this.timesGeneratedValue !== 0 && this.timesGeneratedValue % 3 === 0) {\n          console.info('You still there?');\n        }\n      }\n\n    });\n\n })();\n```\n\nApart from what we've already discussed about the *Values API*, there is also something new: **Value changed callbacks**.\n\nThese callbacks are called whenever a value changes, and also once when the controller is initialized. They are connected automatically given we follow the naming convention of `[valueName]ValueChanged()`. \n\nWe use it to log a message each time the password has been refreshed three times, but they can help with state management in a more complex use case. \n\n\n# Wrapping up\n\nI've created multiple Stimulus controllers for my daily job, and I must say that I always end up pleased with the results. Stimulus encourages you to keep related code together and, combined with the additional HTML markup required, ends up making your code much more readable.\n\nIf you haven't tried it yet, I highly recommend going for it! It offers a different perspective, one of magic üßôüèª‚Äç‚ôÇÔ∏è. \n\n\nThanks for reading me üëãüèº.\n\n\n\n",["283","284","285"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"25 Days of Serverless - Day 02","Solution for the second challenge of 25 Days of Serverless","2019-12-04T05:38:23.139Z","25-days-of-serverless-day-02-i2k","/david_ojeda/25-days-of-serverless-day-02-i2k","https://dev.to/david_ojeda/25-days-of-serverless-day-02-i2k","2019-12-04T05:38:23Z","---\ntitle: 25 Days of Serverless - Day 02\npublished: true\ndescription: Solution for the second challenge of 25 Days of Serverless\ntags: 25 Days Of Serverless, serverless, aws\nseries: 25 Days of Serverless\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/mmifllva7vcih9hqkref.jpeg\n---\n\n*Cover image taken from [Microsoft's 25 Days of Serverless repo](https://github.com/microsoft/25-days-of-serverless/blob/master/week-1/challenge-2/README.md)*\n\n---\n\nIt's time for the second post of this series, hence the solution to the second challenge of the 25 Days of Serverless! Let's get to it üí™üèº.\n\n# Challenge 2: Task Scheduler ‚òïÔ∏è\n\nHere is the [description from their GitHub repo](https://github.com/microsoft/25-days-of-serverless/blob/master/week-1/challenge-2/README.md):\n\n> Lucy's Dilema\n\n> Today we find ourselves in Stockholm, where a little girl named Lucy needs our help!\n\n> Every December 13th, Lucy is tasked with wearing a crown with six lit candles and delivering coffee to all of her family members ‚Äî her mother, father, sister, and brother. Each candle only lasts ten minutes before burning out, and she needs to be careful to keep the candles lit during the delivery time!\n\n> Lucy is somewhat forgetful, though, and the stolen servers mean Lucy's usual reminder app isn't working! With only a few weeks to go before her big night, Lucy is worried how she'll remember everything she needs to do and keep her timing in order. She thought about using sticky notes with color codes to remind her of the things she needs to do, but what if they get mixed up? How can she optimize her tasks using serverless technology?\n\n> It takes Lucy 25 minutes to make a large pot of coffee that will serve everyone, and about four minutes to deliver two cups of coffee (remember that she only has two hands to deliver them!). As mentioned, the candles will need to be relit every ten minutes.\n\n> Create a task scheduler that will tell Lucy exactly when she should relight candles, pour coffee into cups, and deliver batches of coffee. How you want to notify Lucy is up to you: maybe you can send her an SMS via Twilio, or build a webapp that uses WebSockets and browser notifications?\n\nThen there is a section with tips on when to notify what:\n\n> 8:00 AM - start the coffee, set out 4 cups\n\n> 8:25 AM - pour two cups\n\n> 8:30 AM - light the candles\n\n> 8:35 AM - deliver the coffee to Mom and Dad\n\n> 8:39 AM - return to kitchen, fill two more cups\n\n> 8:40 AM - relight the candles\n\n> 8:45 AM - deliver the coffee to Sister and Brother\n\n> 8:49 AM - return to kitchen, take a break!\n\n--- \n\n## My solution\n\nFollowing the same path as the previous challenge, **we're using the AWS SAM CLI to create a serverless app**. This time the following services are used:\n- Lambda\n- CloudWatch Events\n- Simple Notification Service (SNS)\n- Identity Access Management (IAM) Roles\n- CloudFormation\n\n### Creating the app\n\nWe created an app with a quick start template again, only to have the file structure ready to go ‚úÖ.\n\n### Resources\n\nAll resources are defined on the `template.yaml` file. Let's first go through the Lambda serverless function definition:\n\n```yaml\n25DaysOfServerlessDay02:\n  Type: AWS::Serverless::Function\n  Properties:\n    CodeUri: day-02/\n    Handler: app.lambdaHandler\n    Runtime: nodejs12.x\n    Role: !GetAtt 25DaysOfserverlessDay02Role.Arn\n    Events:\n      day02:\n        Type: Schedule\n        Properties:\n          Schedule: cron(0,25,30,35,39,40,45,49 7 13 12 ? *)\n          Name: day-02-schedule\n          Description: Schedule to remember when to serve coffee\n          Enabled: True\n```\n\nThe values that are different from the previous challenge are the `Role` and `Events`.\n\nThe `Role` value uses a CloudFormation function to get the ARN of an IAM role that we're going to create in this same `template.yaml` file; we'll get to that in a little bit.\n\n**This role is the one that the Lambda function will be allowed to assume and it's needed for SNS.**\n\nThe `Event` is where we define the CloudWatch event. Remember, from the tips above, that we want to notify Lucy in specific minutes of the hour. CloudWatch allows us to define a schedule using a cron expression so we can run this Lambda function on those required minutes. Here is the expression:\n\n```bash\n0,25,30,35,39,40,45,49 7 13 12 ? *\n```\n\nYou can check the [AWS specifics of the cron format here](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html#CronExpressions). To be sure on what dates this cron expression will run, you can go to the AWS Console, on the CloudWatch Events > Rules section:\n\n![AWS Console. CloudWatch Events Rules to show when cron expression will run](https://thepracticaldev.s3.amazonaws.com/i/2pfpz11mo7bcjlac1mh0.png)\n\nBy the way, our cron expression runs on the 7th hour since **AWS works with UTC times**, and Stockholm's timezone is UTC + 1:\n\n![Stockholm's timezone](https://thepracticaldev.s3.amazonaws.com/i/bb9t7tla6yxmxdkknsgs.png)\n\nThat will do for the Lambda function. The other resource is the IAM role used to run the function. Here is its definition:\n\n```yaml\n  25DaysOfserverlessDay02Role:\n    Type: AWS::IAM::Role\n    Properties: \n      AssumeRolePolicyDocument: '{\n          \"Version\": \"2012-10-17\",\n          \"Statement\": [\n            {\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                \"Service\": \"lambda.amazonaws.com\"\n              },\n              \"Action\": \"sts:AssumeRole\"\n            }\n          ]\n        }'\n      Description: Allow to send SMS through SNS\n      ManagedPolicyArns: \n        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole                      \n      Policies:\n        - PolicyName: sns_allow_send_sms\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: 'sns:Publish'\n                Resource: '*'\n      RoleName: 25DaysOfserverlessDay02Role\n\n```\n\nThere are three important keys here: `AssumeRolePolicyDocument`, `ManagedPolicyArns`, and `Policies`.\n\nThe first, `AssumeRolePolicyDocument` specifies the trust policy associated with this role, in other words, it defines which entities can assume the role. In this case, the Lambda service. \n\nNext, the `ManagedPolicyArns` is a list of policies already managed by AWS that you can attach to this new role. The specified policy gives basic execution permissions to our function. You can look for these policies on the AWS Console, under the IAM service:\n\n![AWS IAM managed policies](https://thepracticaldev.s3.amazonaws.com/i/pd7yeh3jj5z5f6obj8w7.png)\n\nFinally, the `Policies` section is a custom policy defined by us that allows our role to publish text messages using SNS.\n\n### The Lamda function code\n\nNow the actual code solution for the challenge üëÄ We start by getting the minute when the function was called. We can safely assume that it's running on one of the specified minutes since that's what we defined in the cron schedule:\n\n```javascript\nlet minutes = new Date(event.time).getMinutes();\n\nlet keyMinutes = {\n  0: 'Start the coffee, set out 4 cups',\n  25: 'Pour two cups',\n  30: 'Light the candles',\n  35: 'Deliver the coffee to Mom and Dad',\n  39: 'Return to kitchen, fill two more cups',\n  40: 'Relight the candles',\n  45: 'Deliver the coffee to Sister and Brother',\n  49: 'Return to kitchen, take a break',\n};              \nlet smsPayload = keyMinutes[ minutes ] || '';\n```\n\nHere is a JSON example of the event object used at the beginning:\n\n```json\n{\n  \"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n  \"detail-type\": \"Scheduled Event\",\n  \"source\": \"aws.events\",\n  \"account\": \"123456789012\",\n  \"time\": \"1970-01-01T00:39:00Z\",\n  \"region\": \"us-east-1\",\n  \"resources\": [\n    \"arn:aws:events:us-east-1:123456789012:rule/ExampleRule\"\n  ],\n  \"detail\": {}\n}\n```\n\nTo get the minute we first transform the `time` String from the `event` object into a date, and then we use `getMinutes()` since that's the time granularity we need. \n\nWe then create an object whose keys are the minutes when the function will run, and whose values are the reminders to Lucy. Now, into actually sending them.\n\nWe're using SNS since it's readily available on our Lambda function through the AWS SDK. We create the client at the beginning of the Lamda file:\n\n```javascript\nconst aws = require('aws-sdk');\n```\n\nand we use it like this:\n\n```javascript\nvar params = {\n  Message: smsPayload,\n  PhoneNumber: '+523331412794',\n};                    \n\nvar publishText = await new aws.SNS({apiVersion: '2010-03-31'}).publish(params).promise();   \n```\n\nSending an SMS with SNS only requires the String payload and the phone number üì≤.\n\nWith that, we have a scheduled Lambda function that reminds Lucy what to do next with minute precision ‚è≥.\n\nYou can find all the [final files on my GitHub repo](https://github.com/davidojedalopez/25-days-of-serverless-day-01/tree/day-02).\n\nYou can now go and build and deploy this serverless app with the AWS SAM CLI like in the previous challenge ü•≥\n\n## Recap\n\nThis concludes with the Day 02 challenge from 25 Days of Serverless. \n\nNow that it's my second time using the AWS SAM CLI, I could move faster and get straight to what was needed to solve the problem. \n\nI loved how you can [create events with the CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-generate-event.html) and [use them to locally test your Lamda functions] (https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-invoke.html). Definitely helps a lot since you don't have to deploy everything to test your changes.\n\n---\n\nThanks a lot for reading me! üíö","https://res.cloudinary.com/practicaldev/image/fetch/s--2JUu6Mqq--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/mmifllva7vcih9hqkref.jpeg",["286","287","277"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"25 Days of Serverless - Day 01","Solution for the first challenge of 25 Days of Serverless","2019-12-02T23:26:38.066Z","25-days-of-serverless-day-01-3g4b","/david_ojeda/25-days-of-serverless-day-01-3g4b","https://dev.to/david_ojeda/25-days-of-serverless-day-01-3g4b","2019-12-02T23:26:38Z","---\ntitle: 25 Days of Serverless - Day 01\npublished: true\ndescription: Solution for the first challenge of 25 Days of Serverless\ntags: 25 Days Of Serverless, serverless, aws\nseries: 25 Days of Serverless\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/4ld34pt62433i7mwh1zb.jpeg\n---\n\n*Cover image taken from [Microsoft's 25 Days of Serverless repo](https://github.com/microsoft/25-days-of-serverless/blob/master/week-1/challenge-1/README.md)*\n\n---\n\nYesterday while scrolling through Twitter I found an interesting opportunity to learn about the current state of serverless technologies, it's called **[25 Days of Serverless](https://25daysofserverless.com/)**. \n\nIt's an initiative from Microsoft that consists of one challenge each day from the 1st through the 25th of December. \n\nI decided to give it a try, but using AWS as the cloud provider since it's what I use every day. **The point of the challenge is to learn, not to show what provider is the best.**\n\nSo fasten your seatbelts since I'll be posting my solutions for the next 25 days ü§òüèº\n\n# Challenge 1: A Basic Function\n\nHere is the description from their GitHub repo:\n\n> üé∂ \"I had a little dreidel\n> I made it out of sand\n> And when I tried to spin it\n> It crumbled in my hand!\" üé∂\n\n> Your first stop is Tel Aviv, Israel, where everybody is concerned about Hanukkah! Not only have all the dreidels been stolnen, but so have all of the servers that could replicate spinning a top!\n\n> Have no fear, though: you have the capability to spin not only dreidels, but to spin up serverless applications that can spin a dreidel just as well as you can!\n\n> Your task for today: create a REST API endpoint that spins a dreidel and randomly returns ◊† (Nun), ◊í (Gimmel), ◊î (Hay), or ◊© (Shin). This sounds like a great opportunity to use a serverless function to create an endpoint that any application can call!\n\n## My solution\n\nI used the AWS [Serverless Application Model (SAM)](https://aws.amazon.com/serverless/sam/) CLI since it provides a pre-defined template with built-in best practices for serverless applications and functions. Internally it uses the following services:\n- AWS Lambda\n- AWS API Gateway\n- AWS CloudFormation\n\n### Creating the app\n\nSince it is my **first time developing a serverless application** I went with the [Hello World tutorial](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-getting-started-hello-world.html). It guides you through the **minimum steps needed to have a serverless endpoint up and running**; most of the tutorial is pure magic from the AWS SAM CLI üßôüèª‚Äç‚ôÇÔ∏è.\n\nSo, following this tutorial, I went with a quick start template and the nodejs12.x runtime:\n\n```bash\n$ sam init\nWhich template source would you like to use?\n\t1 - AWS Quick Start Templates\n\t2 - Custom Template Location\nChoice: 1 \n\nWhich runtime would you like to use?\n\t1 - nodejs12.x\n\t2 - python3.8\n\t3 - ruby2.5\n\t4 - go1.x\n\t5 - java11\n\t6 - dotnetcore2.1\n\t7 - nodejs10.x\n\t8 - nodejs8.10\n\t9 - nodejs6.10\n\t10 - python3.7\n\t11 - python3.6\n\t12 - python2.7\n\t13 - java8\n\t14 - dotnetcore2.0\n\t15 - dotnetcore1.0\nRuntime: 1\n```\n\nThis command by itself will create a project structure and the files needed for a serverless app with a single endpoint and Lambda function.\n\nIt looks like this:\n\n```bash\n$ tree\n.\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ events\n‚îÇ   ‚îî‚îÄ‚îÄ event.json                # Sample event for testing\n‚îú‚îÄ‚îÄ hello-world\n‚îÇ   ‚îú‚îÄ‚îÄ app.js                    # AWS Lambda logic\n‚îÇ   ‚îú‚îÄ‚îÄ package.json              # Dependencies\n‚îÇ   ‚îî‚îÄ‚îÄ tests\n‚îÇ       ‚îî‚îÄ‚îÄ unit\n‚îÇ           ‚îî‚îÄ‚îÄ test-handler.js\n‚îî‚îÄ‚îÄ template.yaml                 # SAM template for AWS resources\n\n4 directories, 6 files\n```\n\n### Building the app\n\nThe AWS SAM CLI facilitates this step too:\n\n```bash\nsam build\n```\n\nThis creates the actual artifacts that will be deployed to AWS, which in this case are the AWS Lambda function code and the CloudFormation template. \n\nIf you have Docker installed you can **test your API endpoint locally before deploying to AWS**. Supposing you have so, you can run:\n\n```bash\nsam local start-api\n```\n\nand navigate to the given endpoint on your localhost to see the 'Hello World' response!\n\nAt this point, you are ready to deploy your Hello World serverless app, but that's not what we have been asked to do ü§î\n\nFrom the initial challenge spec: \n\n> Your task for today: create a REST API endpoint that spins a dreidel and randomly returns ◊† (Nun), ◊í (Gimmel), ◊î (Hay), or ◊© (Shin). This sounds like a great opportunity to use a serverless function to create an endpoint that any application can call!\n\nWe have to modify our `app.js` file to solve this problem. My solution goes like this:\n\n```javascript\nexports.lambdaHandler = async (event, context) => {\n    try {\n        let possibleResults = [\"◊†\", \"◊í\", \"◊î\", \"◊©\"]\n        response = {\n            'statusCode': 200,\n            'body': JSON.stringify({\n                result: possibleResults[Math.floor(Math.random() * Math.floor(possibleResults.length))],                \n            })\n        }\n    } catch (err) {\n        console.log(err);\n        return err;\n    }\n\n    return response\n};\n```\n\nI created an array with the four possible results and made the endpoint randomly return one of them in JSON format.\n\n### Deploying the app\n\nAccording to the tutorial you can now go ahead and deploy the app with this command:\n\n```bash\nsam deploy --guided\n```\n\nbut I got an error saying that the IAM role for the Lambda function was not found. As far as I know, I gave permission to the AWS SAM CLI to create the necessary roles to run the app. I also tried creating the IAM role first before deploying the function; however, I got the same error. \n\nI ended up deleting this piece of code from the `Outputs` section of the `template.yaml` file:\n\n```yaml\n  HelloWorldFunctionIamRole:\n    Description: \"Implicit IAM Role created for Hello World function\"\n    Value: !GetAtt HelloWorldFunctionRole.Arn\n```\n\nand this allowed the deployment process to create an IAM role for the function. \n\nWith that out of the way, the deploy command should work correctly and return you an HTTPS endpoint from API Gateway to call your API ü•≥\n\nHere is [my GitHub repo with the final version of all the files](https://github.com/davidojedalopez/25-days-of-serverless-day-01). You can notice that I changed how the endpoint and resources are named, but nothing else.\n\n---\n\n## Recap\n\nThis concludes the first day challenge of 25 Days of Serverless.\n\nAt first, I was overwhelmed by the amount of boilerplate created just to run a single AWS Lambda function, but later I realized that all that code includes very useful things like the HTTPS API endpoint access and the advantage of having every resource codified; similar to *Infrastructure-as-Code*.\n\nI also noticed that some files for testing were created. I haven't yet tried to create tests for a serverless app. That should come soon though!\n\n---\n\nThanks a lot for reading me! I learned a lot just by doing this first challenge, can't wait for the rest! üíô","https://res.cloudinary.com/practicaldev/image/fetch/s--k0KWRU4j--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/4ld34pt62433i7mwh1zb.jpeg",["286","287","277"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"My privacy setup üîê","One of the most precious things in this modern world is data, our own personal data.    With data, co...","2019-08-20T23:42:54.774Z","my-privacy-setup-3k49","/david_ojeda/my-privacy-setup-3k49","https://dev.to/david_ojeda/my-privacy-setup-3k49","2019-08-20T23:42:54Z","**One of the most precious things in this modern world is data, our own personal data.**\n\n![Knowledge is power Game Of Thrones GIF](https://media.giphy.com/media/10fAvEln0lB8Lm/giphy.gif)\n\nWith data, companies can persuade us to do, buy, like, and do whatever fits their interests- and most of the time those interests not really matches ours.\n\nI'm confident that you have already been in this situation: you are talking to a friend about, let's say, going to Disneyland, and a couple hours later while happily scrolling through your Instagram feed you see a sponsored Disneyland add. **It's not a coincidence**. \n\nOr maybe you were chatting with a friend through Whatsapp, talking about babies. Just to receive an email from Amazon about some baby clothes offers. **It's not a coincidence**. \n\n**Many apps read, hear, and collect more information than we can imagine.** Instagram hears what you say, Whatsapp reads what you write, Google knows where you are, and all that data is shared among so many other 3rd parties looking for profit. **Knowledge is power**.\n\nIf you think, \"I don't really care, I have nothing to hide\", **it's not about hiding something**. It's about unauthorized entities knowing everything about you. It's your life.\n\nAnd in order to protect your data, your privacy, I put together this post with the details of my own privacy setup. It includes some rules I follow, as well as apps that help me protect my privacy.\n\n\n---\n\nSome general rules that apply to most of the things you do:\n\n- **Don't give away your information just because it's easy.** If you are signing up for a new service, I recommend you to investigate it before. You don't want to share details about you with a company that is known to sell them to someone else\n\n- **For some temporary signups, you don't need real information.** Some establishments, like coffee shops, ask you for your email address and name to connect to their WiFi, but most times you don't need a real email address since they don't ask for confirmation\n\n- **Check allowed permissions of apps you install**. There are apps that ask for way more than they need. If you can match every permission with a specific feature of the app, then you are probably good to go. [Here is a Lifehacker guide for more information on the topic](https://lifehacker.com/why-does-this-android-app-need-so-many-permissions-5991099)\n\n- **Review privacy settings**. Many apps have a privacy section on its settings where you can change what data can they collect or if targeted ads should be shown to you. Here's Twitter's for example:\n\n![Twitter's privacy settings](https://thepracticaldev.s3.amazonaws.com/i/t8nxxn9aa5ptefiy5zqq.png)\n\n\n**Now let's get to the apps I use!**\n\n\n---\n\n##[Brave](https://brave.com/)![Brave logo](https://thepracticaldev.s3.amazonaws.com/i/3a36yfzdvmxcn3pi6bth.png)\n\n\nAn open source privacy-first browser that comes with ad and tracker blocker by default. I have never missed Chrome or Firefox since I made the switch. \n\nIt's based on Chromium, so all your Developer Tools options are available to you. It also lets you open new tabs with Tor, for a truly private experience. \n\n##[DuckDuckGo](https://duckduckgo.com/about)![DuckDuckGo](https://thepracticaldev.s3.amazonaws.com/i/wkvk5325np71enfttr8n.png)\n\nA privacy-first search engine. DuckDuckGo doesn't store any of your searches, nor does it track you in any way. Every search you make is as it was your first search ever!\n\nIt does not have some quick responses as Google does, but it's totally worth it anyway. I have never missed Google Search either. \n\n##[Signal](https://www.signal.org/)![Signal app logo](https://thepracticaldev.s3.amazonaws.com/i/uppqj8u5f3ht0n24jtb5.png)\n\nSignal is a messaging app that, you guessed it, it's privacy-first; it offers E2E encryption on everything. Plus, it's open source and a nonprofit organization. This app is even recommended by Edward Snowden!\n\nThe downside I have found so far is that not many people are willing to switch or use yet another messaging platform. Whatsapp is way to strong here in M√©xico at least.\n\n##[Bouncer](https://play.google.com/store/apps/details?id=com.samruston.permission&hl=en_US)![Bouncer logo](https://thepracticaldev.s3.amazonaws.com/i/le8kwoixrl4oxqlx491k.png)\n\nThis one is only for Android users. Bouncer is an app that allows you to grant permissions temporarily. It will automatically deactivate permissions after you have used the feature that required them. \n\nFor example, if you were to share your location using Whatsapp, you would need to accept the location permission first, then Bouncer will ask you *once* if you would like to remove or keep the permission after you have finished using it. As soon as you exit the app, Bouncer will remove location permissions from Whatsapp so it can't access them in the background. It's awesome!\n\nMoreover, Bouncer doesn't even require internet permission, so you shouldn't fear of it sharing your information.\n\n##[Tor](https://www.torproject.org/)![Tor Project](https://thepracticaldev.s3.amazonaws.com/i/2e88r004x14pdkm0z6ab.png)\n\nOne of the world's strongest tool for privacy right now. It comes in many forms such as Tor Browser, Tor OS and private tabs with Tor from Brave, and it allows you to navigate the internet freely and with privacy thanks to its multiple layers of encryption.\n\nIt is slower than normal since the traffic goes through a series of relays, but for some people such as bloggers or journalists that must remain private, it's a jewel üíé.\n\n##[NordVPN](https://nordvpn.com) ![NordVPN logo](https://thepracticaldev.s3.amazonaws.com/i/5iis11jwf5veeek5sevt.png)\n\nA VPN will allow you to protect your IP address and to make sure no one can see which websites you visit. It can also help you block ads and protect you on public W-Fi networks. \n\nI use NordVPN and it works just great! It offers hundreds of servers around the world and some more specialty servers such as double VPN, P2P and Onion over VPN.\n\n\n---\n\nThere are some specific apps/companies that I try to avoid whenever possible. Here are some of them:\n\n\n##Google\n\nI personally don't trust many giant tech companies like Google. They make really good products, I can't deny that. However, their business model thrives when users give away their privacy. \n\nTake Gboard for example. This keyboard will have access to your camera, microphone, location and basically to anything you type with it. I admit the keyboard has really great features, but I would rather use something else than this keyboard just from the fact it comes from Google. \n\nI do use Google Maps frequently, I just have many features disabled such as recommendations and location history. \n\n##Social networks\n\nThis should be a no-brainer. Social networks profit from gathering personal information and then using it for ad targeting. I don't have Instagram nor Facebook, but I still have Twitter. I don't use the native apps though, I always check it on the website be it on mobile or desktop.\n\nLeaving your social networks might feel impossible to you since you might have family and friends with whom you talk to or at least follow, and that's okay. I would recommend just not to share too many personal details on your posts.\n\n---\n\n##Closing out\n\n**Your privacy is rapidly becoming a privilege rather than a right, that's why I use all these apps and tips to keep mine.** \n\nI don't pretend to cover everything there is about online privacy on this post, but hopefully it sparks your curiosity to learn and do more to protect what's yours. I still have plenty of things to do, and my next objective is to completely stop using Google Products.\n\nHere are many resources I have studied/read/watched to keep myself informed about this. I highly recommend to **check the DuckDuckGo resources below**, they have immense high quality information about why you should care about privacy.\n\n- DuckDuckGo resources:\n  - [Spread Privacy](https://spreadprivacy.com)\n  - [Three reasons why the nothing to hide argument is flawed](https://spreadprivacy.com/three-reasons-why-the-nothing-to-hide-argument-is-flawed/)\n  - [Privacy newsletter](https://spreadprivacy.com/tag/privacy-newsletter/)\n\n- [Ethical alternatives](https://ethical.net/resources/)\n\n- [Snowden's documentary](https://www.imdb.com/title/tt3774114/?ref_=fn_al_tt_1)\n\n- [Permanent Record, by Edward Snowden](https://www.amazon.com/Permanent-Record-Edward-Snowden/dp/1250237238?SubscriptionId=AKIAILSHYYTFIVPWUY6Q&tag=duckduckgo-brave-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=1250237238)\n\n- [Darknet Diaries podcast](https://darknetdiaries.com)\n\n- [Delete Google Search History](https://spreadprivacy.com/delete-google-search-history/)\n\n*Cover image was generated using [Cover-Image-Generator](https://github.com/PJijin/Cover-Image-Generator/) üíô*\n\n\n**_I hope you find some of what I have shared here useful, and if you know something else I should be doing please leave me a comment!_**\n\n","https://res.cloudinary.com/practicaldev/image/fetch/s--Kl63rBon--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://res.cloudinary.com/practicaldev/image/fetch/s--wSV-PmRl--/c_imagga_scale%2Cf_auto%2Cfl_progressive%2Ch_420%2Cq_auto%2Cw_1000/https://thepracticaldev.s3.amazonaws.com/i/y32lpgvd0qmb1h6oicb7.png",["288"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"What's your take on writing tests for third-party services or integrations?","Let's say you have an application that uses Stripe.  Stripe gives you a dev environment- own API key,...","2019-06-19T01:08:33.818Z","what-s-your-take-on-writing-tests-for-third-party-services-or-integrations-1bco","/david_ojeda/what-s-your-take-on-writing-tests-for-third-party-services-or-integrations-1bco","https://dev.to/david_ojeda/what-s-your-take-on-writing-tests-for-third-party-services-or-integrations-1bco","2019-06-19T01:08:33Z","Let's say you have an application that uses Stripe.\n\nStripe gives you a dev environment- own API key, own dashboard, own data, all separated from your Stripe's live data. \n\n**Do you write tests that interact with this dev environment or do you mock the responses or something alike?**\n\n\nI work on an app that has many integration tests communicating with test/dev/sandbox environments, and they sometimes fail due to errors on their services, not on our own. Now we're discussing if should we mock the responses instead.",["280","289"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},{"name":"280","bg_color_hex":"281","text_color_hex":"282"},"Feature usage tracker","\n\nHey devs, I'm looking for recommendations on feature usage tracking software/li...","2019-03-25T15:14:30.387Z","feature-usage-tracker-253p","/david_ojeda/feature-usage-tracker-253p","https://dev.to/david_ojeda/feature-usage-tracker-253p","2019-03-25T15:14:30Z","Hey devs, I'm looking for recommendations on **feature usage tracking software/libraries**.\n\nThe solution should, at least, allow me to:\n- know how much a given feature is being used\n- know which users are using a given feature\n- let our business people navigate and exploit the information gathered\n- be implemented in both a web and Android app\n\nSo far I'm aware of two potential candidates: [Feature Audit](https://www.featureaudit.com) and [Sales Machine](https://www.salesmachine.io). Feature Audit is still in beta, so still have to be accepted into it. \n\n\n##How do you track feature usage on your apps?",["290"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},{"name":"290","bg_color_hex":"291","text_color_hex":"292"},"Groovy delegation strategy for query re-use in Grails","One way to re-use criteria queries using Groovy closures' delegates in Grails","2019-03-12T17:01:21.662Z","groovy-delegation-strategy-for-query-re-use-in-grails-24ha","/handy/groovy-delegation-strategy-for-query-re-use-in-grails-24ha","https://dev.to/handy/groovy-delegation-strategy-for-query-re-use-in-grails-24ha","2019-03-12T17:01:21Z","---\ntitle: Groovy delegation strategy for query re-use in Grails\npublished: true\ndescription: One way to re-use criteria queries using Groovy closures' delegates in Grails\ntags: groovy, grails, hibernate\ncanonical_url: https://dev.to/handy/groovy-delegation-strategy-for-query-re-use-in-grails-24ha\n---\n\n## The problem\n\nMany of our web app *views*/pages, among other features, consist of a list of entries from a database table. For example, you can go to */customer/list* and get a list and count of your customers. This is fairly common for MVC apps like ours.\n\nWhat we've found is that we end up repeating a lot of code when getting those queries from the database since many of our Domains/tables are filtered by the same fields- current status of the entry (enabled or disabled), belongs to a certain company, user permissions allow him/her to see it, etc.\n\nSo we would end up with something like this to get the information for those *list* views:\n\n```groovy\n    class Customer {\n        Company company\n    \tboolean enabled\n    }      \n\n    def customerList(def params) {\n        Customer.createCriteria().list {\n            eq 'enabled', params.boolean('enabled')\n            eq 'company',  params.company\n            maxResults params.int('max', 10)\n        }\n    }\n    \n    def customerCount(def params){\n        Customer.createCriteria().get {\n            eq 'enabled', params.boolean('enabled')\n            eq 'company', params.company\n            projections {\n                countDistinct 'id'\n            }\n        }\n    }\n```\n\n```groovy\n    class User {\n    \tCompany company\n    \tboolean enabled\n    }\n    \n    def userList(def params) {\n        User.createCriteria().list {\n            eq 'enabled', params.boolean('enabled')\n            eq 'company', params.company\n            maxResults params.int('max', 10)\n        }\n    }\n    \n    def userCount(def params){\n        User.createCriteria().get {\n            eq 'enabled', params.boolean('enabled')\n            eq 'company', params.company\n            projections {\n                countDistinct 'id'\n            }\n        }\n    }\n```\n\n**The body of both list and count methods are almost the same**, the only difference is the table or Domain to which the query goes.\n\nSo we're looking for a way to refactor this code in order to avoid repeating ourselves.\n\n\n## The solution\n\nWe will use a **Groovy closure delegate** to avoid repeating these type of queries. More specifically, we will use something called Closure Delegation Strategy to achieve it. Let's get to it!\n\n\n## Background theory\n\n### Groovy Closures\n\nClosures by themselves deserve a dedicated blog post, but I find Groovy docs to be really clear and to the point. If you haven't worked with closures before or you are looking for a deeper understanding, [please take a look at the docs](http://groovy-lang.org/closures.html#_delegation_strategy).\n\nRight now I will only- briefly -explain some closure concepts.\n\nA Groovy closure looks like this:\n\n```groovy\n    def myClosure = { \"This is a closure\" }\n```\n\nand you can call it like this:\n\n```groovy\n    assert myClosure() == \"This is a closure\"\n```\n\nA Groovy closure defines three main components:\n\n- **this:** The *class* where the closure is defined\n- **owner:** The *enclosing object* where the closure is defined, could be a class or another closure. The difference with **this**: it will return the **direct** enclosing object. If the closure is defined in an inner class, it will return that class, while **this** will return the top-level class.\n- **delegate:** Is a third party object where methods calls or properties are resolved whenever the receiver of the message is not defined\n\nIt's hard to fully understand these concepts without prior experience with them, so here I provide a Groovy snippet where you can play and move things around to fully grasp the closure components. \n\nThe run() method includes some comments to clarify what's going on. You can [copy-paste it here to try it out](https://groovy-playground.appspot.com/)! \n\n```groovy\n    class OuterClass {\n    \n        String name = 'outer class'\n    \n        static void main(String[] args) {}\n    \n        class InnerClass {\n            \n            String name = 'inner class'\n            \n            def ownerClosure = { owner }\n            def thisClosure = { this }\n            def delegateClosure = { delegate }\n            \n            def shoutMyName = {\n                name.toUpperCase()\n            }\n        }\n    \n        def nestedThisClosure = {\n            def closure = { this }\n            closure()\n        }\n    \n        def nestedOwnerClosure = {\n            def closure = { owner }\n            closure()\n        }\n    \n        void run() {\n            def inner = new InnerClass()\n    \n            // Here, **this** and **owner** are equal, that is, the enclosing class (InnerClass)\n            assert inner.thisClosure() == inner\n            assert inner.ownerClosure() == inner\n    \n            // Here, **this** is the enclosing class (OuterClass) and **owner** is the enclosing closure (nestedOwnerClosure)\n            assert nestedThisClosure() == this\n            assert nestedOwnerClosure() == nestedOwnerClosure\n            \n            // The **delegate**, by default, is set to the **owner**\n            assert inner.delegateClosure() == inner.ownerClosure()\n            assert inner.shoutMyName() == 'INNER CLASS'\n            \n            // And even though we can change the **delegate**\n            inner.shoutMyName.delegate = this\n            \n            // We are still getting our InnerClass name, why?\n            assert inner.shoutMyName() == 'INNER CLASS'\n    \n            // The default **resolveStrategy** for closures is **OWNER_FIRST**,\n            // that means that the name field of the **owner** is resolved first.\n            // Luckily, we can also change the **resolveStrategy** of the closure\n            inner.shoutMyName.resolveStrategy = Closure.DELEGATE_FIRST\n            assert inner.shoutMyName() == 'OUTER CLASS'\n    \n        }\n    }\n    \n    new OuterClass().run()\n```\n\nNow that we have more knowledge of the power of closures, we can implement our delegation strategy to re-use our queries.\n\n## The implementation\n\nAs mentioned at the beginning, we have two very similar Domains with similar fields and we need to get both a list and count of those Domains at some point.\n\nTo solve this, we're going to **create a closure** to get the list and another closure for the count. Then, **we're changing the closure's delegate** according to the Domain we are querying.\n\nLet's suppose we have a ListService where we're going to manage all this logic.\n\nHere are the closures:\n\n```groovy\n    class ListService {\n    \n    \tprivate def getList = { def params ->\n    \t    createCriteria().list {\n    \t        eq 'company', params.company\n    \t        if(!params.boolean('showDisabled', false)) {\n    \t            eq 'enabled', true\n    \t        }\n                maxResults params.int('max', 10)\n    \t    }\n    \t}\n    \t\n    \tprivate def getCount = { def params ->\n    \t    createCriteria().get {\n    \t        eq 'company', params.company\n    \t        if(!params.boolean('showDisabled', false)) {\n    \t            eq 'enabled', true\n    \t        }\n    \t        projections {\n    \t            countDistinct 'id'\n    \t        }\n    \t    }\n    \t}\n    \n    }\n```\n\nNow, we need to change the delegate of the closures dynamically, depending on the Domain to query:\n\n```groovy\n    class ListService {\n    \n    \t[...]\n    \n    \tdef getDomainList(def params, def domain) {\n    \t    getList.delegate = domain\n    \t    getList(params)\n    \t}\n    \t\n    \tdef getDomainCount(def params, def domain) {\n    \t    getCount.delegate = domain\n    \t    getCount(params)\n    \t}\n    \n    }\n```\n\nFinally, we're going to use this service from our controller to return the values to our list view:\n\n```groovy\n    class CustomerController {\n    \n    \tdef listService\n    \n    \tdef list() {\n    \t\t[\n    \t\t\tlist: listService.getDomainList(params, Customer),\n    \t\t\tcount: listService.getDomainCount(params, Customer)\n    \t\t]\n    \t}\n    \n    }\n```\n    \n```groovy\n    class UserController {\n    \n    \tdef listService\n    \n    \tdef list() {\n    \t\t[\n    \t\t\tlist: listService.getDomainList(params, User),\n    \t\t\tcount: listService.getDomainCount(params, User)\n    \t\t]\n    \t}\n    \n    }\n```\n\nThe list view now has everything it needs to render each result and paginate it!\n\n\n## Summary\n\nThe final flow is this:\n\n1. A request comes to controller, e.g. UserController to get user's list\n2. Controller **uses ListService** to query the database. It forwards the params from the request and **specifies the Domain** to query\n3. ListService users the given Domain to **change the closure's delegate** and proceeds to execute the closure\n4. Closure sees the createCriteria() method call and seeks for the object that implements it. Since we didn't change the closure's resolve strategy, **it will look on the owner first**. \nThe owner, our ListService, doesn't implement a createCriteria() method, so the closure **now looks at the delegate**. \nThe **delegate is our Domain**, and it has a createCriteria method, so it uses it and returns our results all the way back to our controller.\n\n\nNow we have two closures that are being used by multiple Domains to get similar data from the database. \n\n---\n\nThis is only one of many powerful use cases of closure delegates in Groovy. Have you used this feature before? If so, let me know in the comments!\n\n\n\n**Thanks for reading me ‚ù§Ô∏è**",["293","294","295"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},{"name":"296","username":"297","slug":"297","profile_image":"298","profile_image_90":"299"},"Go get your .dev domain!",".dev Top Level Domain (TLD) is now generally available","2019-02-28T23:11:00.487Z","go-get-your-dev-domain-5hef","/david_ojeda/go-get-your-dev-domain-5hef","https://dev.to/david_ojeda/go-get-your-dev-domain-5hef","2019-02-28T23:11:00Z","---\r\ntitle: Go get your .dev domain!\r\npublished: true\r\ndescription: .dev Top Level Domain (TLD) is now generally available\r\ntags: dev, domain, portfolio\r\n---\r\n\r\nAs of today, the Top Level Domain (TLD) **.dev** is available at a reasonable price. [Go get yours!](https://get.dev/) ü§ì\r\n\r\nAlong with the coolness of having your business, personal page, side-project or portfolio on a .dev domain, it also offers built-in security. That is, HTTPS is enforced for all connections to your .dev site. \r\n\r\nI just bought mine for like 15 USD/year- [davidojeda.dev](https://davidojeda.dev). Right now it only redirects to my personal page currently hosted at [davidojeda.mx](https://davidojeda.mx), but will make the .dev domain the main one!\r\n\r\n\r\nHave you bought one yet?\r\n\r\n\r\n\r\n",["300","301","302"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"On handling outages: a case study","Ramblings about ways to communicate outages using latest Basecamp's outage as an example","2018-11-09T22:50:06.397Z","on-handling-outages-a-case-study-59cb","/david_ojeda/on-handling-outages-a-case-study-59cb","https://dev.to/david_ojeda/on-handling-outages-a-case-study-59cb","2018-11-09T22:50:06Z","---\ntitle: On handling outages: a case study\npublished: true\ndescription: Ramblings about ways to communicate outages using latest Basecamp's outage as an example\ntags: outage, communication\ncanonical_url: https://dev.to/david_ojeda/on-handling-outages-a-case-study-59cb\n---\n\nIf you happen to use Basecamp 3 to manage your projects, you might have noticed a huge outage on November 8th, 2018; **it lasted almost 5 hours**.\n\nThe issue was that they failed to use bigint for the primary keys of their tables so they ran out of IDs. The *TLDR* solution, taken from David Heinemeier- DHH, creator of Ruby on Rails and Founder and CTO at Basecamp: \n\n> We took half of our replicas offline, did the 3h migration, put them back online, will now be converting the other half of the fleet.\n\nAnd I'm not writing this to expose and/or throw **** at them. \n\nI'm writing this to **applaud their communication and openness** about the whole outage.\n\nI'm writing this to expose how **over-communication, honesty, humbleness and clarity DO make a difference**, specially on difficult situations.\n\n***\n\nTo give you some context, the first notice on their Twitter account about something going wrong was at 5:40 AM on November, 8th:\n\n{% tweet 1060527469361537024 %}\n\nFrom that tweet and until everything was working again, there were 15 more tweets with constant updates! With the last one being at 10:47 AM, November 8th, signed by DHH himself:\n\n{% tweet 1060604787819827201 %}\n\nAll that information is a **huge deal**. You know they are working really hard to get everything up and going, and you might also know that outages can get really messy. \n\nDespite all the chaos that was probably happening, they kept posting updates with specific details of the cause and solution being taken- on their Twitter account, status page and on their blog. And not only that, DHH was also posting some more technical details about the outage to the point where **he links to the pull request that could have saved everything**:\n\n{% tweet 1060565296048562177 %}\n\n***\n\nI find all this **incredibly valuable and relieving**. Even though it was a really long outage, they handled each and every customer interaction gracefully. I could not get upset with them with so much information about the problem/solution being provided. \n\nHell, that morning **I was even more productive because Basecamp remained read-only**; I could check on what was pending on my side and just get to it with no distractions.\n\nI've been part, and cause, of outages at my company and it's really stressful. And we don't even handle the amount of traffic Basecamp 3 does.\n\nSo, as DHH states it, **this is a reminder to stay humble**. We could be the next ones involved in a situation like this. **We all make mistakes, that's inevitable**, but knowing how to properly communicate them is what matters in the long run.\n\n*** \n\nHope you have enjoyed this short rambling ‚ù§Ô∏è\n",["303","304"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"It's obviously simple!","The use of discouraging words","2018-08-17T22:54:57.127Z","its-obviously-simple-2n8a","/david_ojeda/its-obviously-simple-2n8a","https://dev.to/david_ojeda/its-obviously-simple-2n8a","2018-08-17T22:54:57Z","---\ntitle: It's obviously simple!\npublished: true\ndescription: The use of discouraging words\ncanonical_url: https://dev.to/david_ojeda/its-obviously-simple-2n8a\ntags: beginners, tips\n---\n\n\nA couple of days ago I was going through some tutorials and guides on various software topics and got frustrated because I could not figure something out. But it was not that mere act that annoyed me, it was due to the way the instructions were stated: **JUST** need to change the configuration of your server.\n\nYou know, you **JUST** need to make this; you **JUST** need to modify that; the server will **OBVIOUSLY** crash.\n\n<img src=\"https://thepracticaldev.s3.amazonaws.com/i/2p8j4ginx0mwl3k9ys53.jpeg\" alt=\"Obviously a meme\" style=\"display: block;margin-left: auto;margin-right: auto;width: 30%;\">\n\nNot because you find something obvious or simple means that everyone else will. Words like just, obviously and simply are generally discouraging- specially for beginners that are starting to piece different things together.\n\nMoreover, I don't think those words add any value to your writing. Does it make your point clearer if you state that it should be obvious? **No**. On the contrary, your reader might feel like a fool because he/she didn't find it obvious at all.\n\nWhile thinking about this I decided to do a little page where you can paste your text and it will highlight words like *obvious*, *simply*, *just*, etc. I decided to go with React/Redux, some deep learning algorithms and everything running serverless. **Just kidding**, it's an static website with inline CSS and JavaScript that uses a Regex üôÉ [Check it out here!](https://simply.davidojeda.mx/)\n\nIn my opinion, we should try to avoid those words as much as we can to stop discouraging others and to add more value to our ideas. Also, you use fewer words.\n\n\nThanks for reading me! ‚ù§Ô∏è\n",["305","306"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"AWS S3 Pt. 1 - The Basics","Basic concepts of AWS Simple Storage Service (S3)","2018-08-17T21:03:06.267Z","aws-s3-pt-1---the-basics-55bp","/david_ojeda/aws-s3-pt-1---the-basics-55bp","https://dev.to/david_ojeda/aws-s3-pt-1---the-basics-55bp","2018-08-17T21:03:06Z","---\ntitle: AWS S3 Pt. 1 - The Basics\npublished: true\ndescription: Basic concepts of AWS Simple Storage Service (S3)\ntags: [aws, s3]\ncanonical_url: https://dev.to/david_ojeda/aws-s3-pt-1---the-basics-55bp\n---\n\n*Part one of this series covers S3 basics and a general use case.*\n\n---\n\n\n# What's AWS S3?\nAWS **S**imple **S**torage **S**ervice, called **S3**, is an object storage solution to reliably store and retrieve any amount of data.\n\n# What can it do?\nIt can store your files, build packages, reports, images, and any type of data you can think about for later retrieval with a guaranteed 99.999999999% durability. Also, it can restrict access to specific data with very flexible rules.\n\n# Why use it?\nS3 is extremely reliable and flexible. You want to use it if you at some point need to store and retrieve:\n- Huge amounts of data for analytics\n- Files for customers to access\n- Build files for your applications\n- Assets such as images and videos\n\nAlso, it has tons of integrations with other services within AWS.\n\n# Some basic S3 concepts\n- ## Buckets\n  A Bucket is like a top level directory in Linux in the sense that it is a node in level one. A bucket is then the \"directory\" that stores a group of objects or more directories (with no quotes since these are proper directories now). More clarification below.\n\n- ## Objects\n  Objects are the files itself. A bucket can contain many different objects.\n\nBucket and objects example:\n\n![S3 URL explained](https://thepracticaldev.s3.amazonaws.com/i/wx0mkto03h9zi2vescrv.png)\n\n- ## Bucket Policies\n  S3 bucket policies are the set of rules that explicitly define who has or not access to your bucket and to objects within that bucket.\n\n- ## ACLs\n  **A**ccess **C**ontrol **L**ists is yet another way to define access to your buckets and objects. However, this is a legacy access control mechanism, so it's best to focus on bucket policies. The cases in which ACLs are needed are, for example, when a bucket policy grows too large- they are limited to 20 kb in size. Or when you want to restrict access to specific objects within a bucket.\n\n- ## Lifecycle Rules\n  Lifecycle rules are actions that S3 can apply to a group of objects depending on how much time they have been stored. For instance, you can delete objects that have been on your buckets for more than 90 days. \n\nApart from these concepts, one of the most important things to know about S3 is its **consistency model**.\n\nThe consistency model of S3 is called **Read-after-Write consistency**. For example, if you issue a PUT request to create an object on a bucket, the next GET request will **ALWAYS** have the desired object. \n\nHowever, if you try to issue a GET first (object being non-existent), then a PUT and then another GET, you *MIGHT* not found the desired object. Issuing the request in this order, the consistency model is now called eventual consistency. \n\nIn other words:\n\nRead-after-Write consistency:\n- PUT /my-bucket/photo.png -> 200\n- GET /my-bucket/photo.png -> 200\n\nEventual consistency:\n- GET /my-bucket/photo.png -> 404\n- PUT /my-bucket/photo.png -> 200\n- GET /my-bucket/photo.png -> 404\n\nYou also get eventual consistency when you delete an existing object. That is, you *MIGHT* see an object listed on your bucket even though you already deleted it a couple of seconds ago.\n\nThis is because changes made to your S3 buckets need some time to propagate and replicate through AWS servers.\n\n# Some S3 use cases\n\n- Store AWS Load Balancer logs for further analysis\n- Host static websites\n- Store assets for a static web page\n- Store exported data for your customers\n\n#Wrap up\n\nThis covers the very basics of S3 which are enough to get started with the service. S3 is one of the most used services of AWS due to its reliability, durability and integration with many other services inside and outside AWS.\n\n\n**Thanks for reading me!** ‚ù§Ô∏è\n\n---",["277","278"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"AWS IAM Pt. 2 - A Practical Example","Use case solution for AWS Identity Access Management (IAM)","2018-07-31T15:54:59.970Z","aws-iam-pt-2---a-practical-example-13b6","/david_ojeda/aws-iam-pt-2---a-practical-example-13b6","https://dev.to/david_ojeda/aws-iam-pt-2---a-practical-example-13b6","2018-07-31T15:54:59Z","---\ntitle: AWS IAM Pt. 2 - A Practical Example\npublished: true\ndescription: Use case solution for AWS Identity Access Management (IAM)\ntags: [aws, iam]\ncanonical_url: https://dev.to/david_ojeda/aws-iam-pt-2---a-practical-example-13b6\n---\n\n*Part one of this series covers IAM basics and a general use case:*\n{% link https://dev.to/david_ojeda/aws-iam-pt-1---the-basics-139h %}\n\n*Part two is the implementation of the use case in part one, that is, the creation of users, groups and policies to restrict access to some AWS services.*\n\n---\n\n\nOn previous post I explained the basics of AMI and described an use case for it. Now, we're going to implement the actual solution for that problem.\n\nAs a quick recap, we have four developers that need shared and not shared access to AWS services, and an accountant that has very limited access. Specifically:\n- **DevOps developers**: Console and programmatic access to ElasticBeanstalk, EC2, S3 and SQS\n- **Web developers**: Console and programmatic access to ElasticBeanstalk and S3\n- **Mobile developers**: Programmatic access to S3 and AWS mobile services such as Cognito\n- **Accountant**: S3 read-only access to the AWS billing reports bucket\n\nLet's get started.\n\n---\n\n## Create groups\nFirst thing we need is to create the groups- let's start with the **DevOps** group.\n1. Go the IAM console and select the groups section on the sidebar\n2. Press the \"**Create New Group\"** button\n\n![][iam-dashboard-group-creation]\n\n### Name your group\nOur group is going to be called *DevOps*:\n\n![][iam-dashboard-group-name]\n\n### Attach a policy\nThis is where it starts to get interesting. Remember that a policy is the set of \"rules\" that will dictate which services and actions are allowed- for the group in this case.\n\nOn the next screen you will get a seemingly endless list of already created policies. These policies are managed by AWS, that is, they already contain rules for specific permissions you may need. Luckily for us, there are polices that perfectly fits our needs. According to the problem details, the policies needed for the DevOps group are:\n- **AmazonS3FullAccess**: Full access to S3\n- **AWSElasticBeanstalkFullAccess**: Full access to ElasticBeanstalk\n- **AmazonEC2FullAccess**: Full access to EC2\n- **AmazonSQSFullAccess**: Full access to SQS\n\nSelecting these policies you are saying: *All users in this group will have full access to S3, EC2, ElasticBeanstalk and SQS.* Go for it.\n\n**NOTES**:\n- You can proceed to the next step without attaching any policy. That means that the group will have no permissions at all.\n- If the name of a policy is not descriptive enough you can always go to the policies section of the IAM dashboard and look for the details:\n\n![][iam-policy-details]\n\n### Review group\nLast step in group creation is to review and make sure the name and policies are the ones we intended to set. So, make sure the name and policies are ones we intended to set üòõ\n\nYou now have the **DevOps group** created. Go ahead and create the two developers groups remaining. The general process is the same, but you need a different name and a different set of policies.\n\n---\n\n## Create users\nTime to create each of our users.\n1. Go the IAM console and select the users section on the sidebar\n2. Press the \"**Add user\"** button\n\n![][iam-dashboard-user-creation]\n\n### Name your user and select access type\nOur first user will be *Sally*- a **DevOps** engineer- and these are the configurations needed according to the details of the problem previously stated:\n\n![][iam-user-creation-step1]\n\nSo the user will have programmatic and console access. The user will first enter with an autogenerated password, and then asked to reset it.\n\n### Set permissions\nAt this point you need to define the permissions for this new user. You can either:\n- Add user to a group\n- Copy permissions from existing user\n- Attach existing policies directly\n\nSince you already did the heavy lifting of creating a group with the needed policies, we're going to select the first option: Add user to a group. Go ahead and select the group you created on the previous steps:\n\n![][iam-user-creation-step2]\n\n### Review\nAs in the groups creation, review everything is configured as intended and proceed to create the user.\n\nAt this point you will be given the credentials of the user as well as its password. I recommend you to download and email them to the person the AWS user is intended.\n\nYou now have your first user assigned to the adequate group according to its job requirements. You can now proceed to create the remaining users and add them to the required groups.\n\n---\n\n## The accountant group and user\nThe accountant only requires read-access to a specific bucket- that's a very limited permission scope. There is no AWS managed policy to manage this case. **It's time to create your own policy**.\n\n## Create a custom policy\nTo create an IAM policy:\n1. Go the IAM console and select the *policies* section on the sidebar\n2. Press the \"**Create policy\"** button\n\n![][iam-dashboard-policy-creation]\n\nNow you are redirected to the policy creation page. There are two ways to create a policy on this page:\n- Visual editor\n- JSON document\n\nWe're going to use the Visual editor option because I think is more friendly. Here, he need to select to which service(s) we want access to, to what specific actions, and to what specific resources of this/these service(s) we can access.\n\nWe want S3 read-only access to the billing reports bucket.\n\n**NOTE**: I'm assuming you have at least one S3 bucket with which you can try this exercise. If you don't have any, please go to S3 and create one with the default settings.\n\nFirst permission you need to add is this:\n\n![][iam-dashboard-policy-creation-permission1]\n\nThe **ListAllMyBuckets** and **GetBucketLocation** actions combined with the **All resources** option allows the user to see every bucket that exists on your account. You actually need this permission if you want the user to be able to access the bucket through the AWS console. Don't worry, they will no be able to access anything but the bucket names.\n\nNow, add another permission with the bottom right button. This time you only need the **ListBucket** action and to define the bucket ARN you need access to. My bucket is called *my-company-billing*. So, the options look like this:\n\n![][iam-dashboard-policy-creation-permission2]\n\nYou can get your bucket ARN by selecting your bucket on S3. The ARN is **arn:aws:s3:::{YOUR_BUCKET_NAME}**.\n\nThis permission allows users to list the contents of a bucket, but not to access them yet. We're missing one last permission, so let's add it.\n\nLast but not least, this permission will allow the user to actually access the objects on the desired bucket:\n\n![][iam-dashboard-policy-creation-permission3]\n\nWe're using the wildcard \"**\\***\" after the bucket name as our resource ARN to indicate that we want access to every object in the bucket.\n\nGo to next step, name your policy, add an useful description and finish the policy creation! I recommend you to have a naming convention for every resource you create. It doesn't matter much which convention you choose, but **stick with it**. I use *camel caps* (ThisIsCamelCaps) because AWS managed policies are named that way.\n\n**TIP**: You can use the [AWS Policy Simuator](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html) to test your policies and verify they only provide access to the resources they need to.\n\n### Use custom policy\nYou now have your accountant custom policy with S3 read-only access. Last thing you need to do to solve the stated problem is to create your accountant group and user, and tie them together. You can do that with the knowledge acquired so far üòâ\n\n# Wrap-up\nSo far you have created four groups- three for developers and one for your accountant. Also, you created a user for each of your employees and added them to the adequate group according to their job needs.\n\nAll your users should now have permissions to perform their jobs and everyone should be happy üëèüèº\n\n**Thanks for reading me!** ‚ù§Ô∏è\n\n[iam-dashboard-group-creation]: https://davidojeda.mx/assets/iam/pt2/pt2-1.png \"IAM Dashboard with group section selected\"\n[iam-dashboard-group-name]: https://davidojeda.mx/assets/iam/pt2/pt2-2.png \"IAM Group creation - Group name\"\n[iam-policy-details]: https://davidojeda.mx/assets/iam/pt2/pt2-3.png \"IAM policy details - AWS Cognito Power User\"\n[iam-dashboard-user-creation]: https://davidojeda.mx/assets/iam/pt2/pt2-4.png \"IAM Dashboard with user section selected\"\n[iam-user-creation-step1]: https://davidojeda.mx/assets/iam/pt2/pt2-5.png \"IAM User creation- step one\"\n[iam-user-creation-step2]: https://davidojeda.mx/assets/iam/pt2/pt2-6.png \"IAM User creation- step two\"\n[iam-dashboard-policy-creation]: https://davidojeda.mx/assets/iam/pt2/pt2-7.png \"IAM Dashboard with policies section selected\"\n[iam-dashboard-policy-creation-permission1]: https://davidojeda.mx/assets/iam/pt2/pt2-8.png \"IAM Policy creation - Permission one\"\n[iam-dashboard-policy-creation-permission2]: https://davidojeda.mx/assets/iam/pt2/pt2-9.png \"IAM Policy creation - Permission two\"\n[iam-dashboard-policy-creation-permission3]: https://davidojeda.mx/assets/iam/pt2/pt2-10.png \"IAM Policy creation - Permission three\"\n",["277","307"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"Road to AWS Certification","Entry post for series of posts about AWS","2018-07-30T20:56:34.840Z","road-to-aws-certification-2438","/david_ojeda/road-to-aws-certification-2438","https://dev.to/david_ojeda/road-to-aws-certification-2438","2018-07-30T20:56:34Z","---\ntitle: Road to AWS Certification\npublished: true\ndescription: Entry post for series of posts about AWS\ntags: [aws]\ncanonical_url: https://dev.to/david_ojeda/road-to-aws-certification-2438\n---\n\nI've worked with AWS at my job for around two years. I don't proclaim myself an expert or something alike, but surely I've learned a lot during this time. \n\nA couple of months ago I decided to commit and study to get an AWS certification- AWS Solutions Architect. That's why I'm creating a series of posts such as tutorials, guides and tips/tricks on AWS. \n\nThere are tons of things I need to learn and deeply understand, and I think teaching them is the most effective way to learn them.\n\n**Would love any feedback, corrections and/or suggestions on the series' posts!** Also, I'm going to re:Invent 2018 by myself, if anyone wants to hang out there feel free to talk to me!\n\nThanks a lot, fam! ‚ù§Ô∏è\n\nI will be updating this post whenever I create a new post for the series.\n\n- **IAM**\n\n{% link https://dev.to/david_ojeda/aws-iam-pt-1---the-basics-139h %}\n\n{% link https://dev.to/david_ojeda/aws-iam-pt-2---a-practical-example-13b6 %}\n\n- **S3**\n\n{% link https://dev.to/david_ojeda/aws-s3-pt-1---the-basics-55bp %}\n",["277"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"AWS IAM Pt. 1 - The Basics","Basic concepts of AWS Identity Access Management (IAM)","2018-07-30T20:54:01.064Z","aws-iam-pt-1---the-basics-139h","/david_ojeda/aws-iam-pt-1---the-basics-139h","https://dev.to/david_ojeda/aws-iam-pt-1---the-basics-139h","2018-07-30T20:54:01Z","---\ntitle: AWS IAM Pt. 1 - The Basics\npublished: true\ndescription: Basic concepts of AWS Identity Access Management (IAM)\ntags: [aws, iam]\ncanonical_url: https://dev.to/david_ojeda/aws-iam-pt-1---the-basics-139h\n---\n\n*Part one of this series covers IAM basics and a general use case.*\n\n*Part two is the implementation of the use case in part one, that is, the creation of users, groups and policies to restrict access to some AWS services:*\n\n{% link https://dev.to/david_ojeda/aws-iam-pt-2---a-practical-example-13b6 %}\n\n\n---\n\n\n#What's AWS IAM?\nAWS **I**dentity and **A**ccess **M**anagement, called **IAM**, is a feature of AWS that allows you to have fine-grained control over who can access any of your AWS resources and to what extent. Also, it's **free**.\n\n#What can it do?\nIt can **allow and restrict access** to specific services and actions to specific users or roles- more on this below.\n\n#Why use it?\nYou don't want every user to be able to do absolutely everything on your account. Usually you want a set of users- or group of users- to execute a set of specific actions on selected services. **That's why you need IAM**.\n\n#Some basic IAM concepts\nOnce you start using IAM you're going to stumble upon some of these concepts and you need to understand them very well to know when to use one or the other.\n\n- ##Policies\n  **Policies are the cornerstone of IAM**. They are the set of rules and restrictions that define the level of access to services and actions to your AWS resources.\n\n- ##Users\n  You can think of IAM users as **physical individuals** that need some level of access to your AWS resources either through the console and/or programmatically- e.g., John needs to check if the servers are healthy. **He needs EC2 access**. *(All AWS acronyms used on this post are listed at the end)*\n\n- ## Groups\n  Groups are no more than a collection of users that share the same restrictions. Using groups helps you re-use your policies- e.g., your networking team need to do a security audit on your network settings. **They all need VPC access**.\n\n- ## Roles\n  Roles are somehow similar to users, except for the fact that roles are used to restrict access from resource to resource- e.g., your server needs to notify a queue of an event. **Your EC2 servers need SQS access**.\n\nWe're not yet gonna dive on how to create any of these entities. First, let me show you a common situation where IAM can greatly help you.\n\nLet's suppose you're the CTO of a company with:\n- Four developers- Sally, Maria, John and Jane\n- One salesperson- Peter\n- One accountant- Mary\n\nThe developers have different roles on your company: Sally is a DevOps engineer, John and Maria are web developers, and Jane is a mobile developer.\n\nYou all use AWS, but each needs a different set of services. You don't want every employee to have acccess to every resource, so you decide to use IAM to solve this problem.\n\n# But how?\nWith IAM, you create a **group** for each job role and attach a **policy** for the specific access needed. Then you add users to the adequate group.\n\nLet's define what do each of these groups need:\n\n- **DevOps developers**: Console and programmatic access to ElasticBeanstalk, EC2, S3 and SQS\n- **Web developers**: Console and programmatic access to ElasticBeanstalk and S3\n- **Mobile developers**: Programmatic access to S3 and AWS mobile services such as Cognito\n- **Accountants**: S3 read-only console access to an AWS billing bucket\n\nWith these specifications in mind, we can proceed now to create each group and user and assign, or not, console and programmatic access to AWS as well as the needed policies.\n\nWhat about the salesperson? The salesperson doesn't need AWS access at the moment, so no user for him üôÉ\n\n#Wrap up\n\nThis was a very broad overview on how IAM can help you manage and control access to your AWS resources. I know this post is very general and doesn't dive deep into how you *actually* achieve this. That's why we're now going to implement this solution on the next blog post!\n\n{% link https://dev.to/david_ojeda/aws-iam-pt-2---a-practical-example-13b6 %}\n\n\n**Thanks for reading me!** ‚ù§Ô∏è\n\n---\n\n<small>IAM: Identity Access Management - Permissions within AWS</small>\n<small>S3: Simple Storage Service - AWS storage solution</small>\n<small>EC2: Elastic Compute Cloud - AWS computational cloud solution</small>\n<small>ElasticBeanstalk: AWS-managed computational cloud solution</small>\n<small>SQS: Simple Queue Service - AWS queue solution</small>\n<small>VPC: Virtual Private Cloud - AWS network management solution</small>\n<small>Cognito: AWS solution for mobile sign-in and sign-up</small>\n\n",["277","307"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"Make Requests from Docker Container Running on Jenkins","Make requests from Docker container running on Jenkins","2018-05-25T21:43:16.647Z","make-requests-from-docker-container-running-on-jenkins-3ln1","/david_ojeda/make-requests-from-docker-container-running-on-jenkins-3ln1","https://dev.to/david_ojeda/make-requests-from-docker-container-running-on-jenkins-3ln1","2018-05-25T21:43:16Z","---\ntitle: Make Requests from Docker Container Running on Jenkins\npublished: true\ndescription: Make requests from Docker container running on Jenkins\ntags: docker, jenkins, iptables\ncanonical_url: https://dev.to/david_ojeda/make-requests-from-docker-container-running-on-jenkins-3ln1\n---\n\nThis post is about a specific problem I encountered where I **couldn't make any requests from my Docker container to the outside world**. It was my first time working with Jenkins Pipelines and decided to use Docker as my isolation agent.\n\nSome facts related to my environment:\n- Jenkins is running on Tomcat, not on a Docker container\n- I have port redirection (80 to 8080 and 443 to 8443) using **iptables**\n\n## Code in question\n\nThe relevant part of my Jenkinsfile is this:\n\n```groovy\nstage('build and test apps') {\n  failFast true\n  parallel {\n    stage('front end') {\n      steps {\n        sh 'npm install --prefix front_end/'\n        sh 'npm run build --prefix front_end/'\n        sh 'npm run test --prefix front_end/'\n      }\n    }\n\n    stage('back end') {\n      steps {\n        sh 'npm install --prefix back_end/'\n        sh 'npm run test --prefix back_end/'\n      }\n    }\n  }\n}\n```\n\n## The logs\n\nThe requests needed on the `npm install` command were **failing with 403 http errors** and this log was appearing:\n\n```text\nnpm ERR! Unexpected token < in JSON at position 0\nnpm ERR! <html><head><meta http-equiv='refresh' content='1;url=/login?from=%2Freact-scripts'/><script>window.location.replace('/login?from=%2Freact-scripts');</script></head><body style='background-color:white; color:white;'>\nnpm ERR!\nnpm ERR!\nnpm ERR! Authentication required\nnpm ERR! <!--\nnpm ERR! You are authenticated as: anonymous\nnpm ERR! Groups that you are in:\nnpm ERR!\nnpm ERR! Permission you need to have (but didn't): hudson.model.Hudson.Read\nnpm ERR!  ... which is implied by: hudson.security.Permission.GenericRead\nnpm ERR!  ... which is implied by: hudson.model.Hudson.Administer\nnpm ERR! -->\nnpm ERR!\nnpm ERR! </body></html>\nnpm ERR!\nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     <https://github.com/npm/npm/issues>\n```\n\nAfter reading the logs, the first thing I thought was: this is something related to permissions of the user running the Docker container- **tomcat** in my case -but they weren't.\n\nAfter debugging for quite a while, I stumbled upon <a href=\"https://stackoverflow.com/questions/44264082/why-is-jenkins-on-the-docker-host-responding-to-http-requests-from-inside-contai\" target=\"_blank\">some divine light on StackOverflow</a>. Thanks to this, I found that I was redirecting **all** port 80 and 443 trafic from **everywhere** to their corresponding 8080 and 8443 ports.\n\n## The solution\n\n**Alter the iptables to create a negated rule and avoid redirects from the Docker subnet**.\n\nFirst, check your current iptables with this command: ```iptables -t nat -L -n --line-numbers```\n\n```\nChain PREROUTING (policy ACCEPT)\nnum  target     prot opt source               destination\n1    REDIRECT   tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:80 redir ports 8080\n2    REDIRECT   tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:443 redir ports 8443\n3               tcp  --  0.0.0.0/0            0.0.0.0/0\n4    DOCKER     all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCAL\n\nChain INPUT (policy ACCEPT)\nnum  target     prot opt source               destination\n\nChain OUTPUT (policy ACCEPT)\nnum  target     prot opt source               destination\n1    REDIRECT   tcp  --  0.0.0.0/0            127.0.0.1            tcp dpt:443 redir ports 8443\n2    REDIRECT   tcp  --  0.0.0.0/0            127.0.0.1            tcp dpt:80 redir ports 8080\n3    DOCKER     all  --  0.0.0.0/0           !127.0.0.0/8          ADDRTYPE match dst-type LOCAL\n\nChain POSTROUTING (policy ACCEPT)\nnum  target     prot opt source               destination\n1    MASQUERADE  all  --  172.17.0.0/16       0.0.0.0/0\n\nChain DOCKER (2 references)\nnum  target     prot opt source               destination\n1    RETURN     all  --  0.0.0.0/0            0.0.0.0/0\n```\n\nThe value **0.0.0.0/0** on the source column refers to **all** trafic. So, in my case, I need to replace the first two entries of both the PREROUTING and OUTPUT chain:\n\n**Note**: The default Docker subnet is **172.17.0.0/16**. If you changed the default configurations make sure to change them in the commands also.\n\n**PREROUTING**\n\n```\niptables -t nat -R PREROUTING 1 ! -s 172.17.0.0/16 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8080\n```\n\n```\niptables -t nat -R PREROUTING 2 ! -s 172.17.0.0/16 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 8443\n```\n\n**OUTPUT**\n\n```\niptables -t nat -R OUTPUT 1 ! -s 172.17.0.0/16 -d 127.0.0.1/32 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 8443\n```\n\n```\niptables -t nat -R OUTPUT 2 ! -s 172.17.0.0/16 -d 127.0.0.1/32 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8080\n```\n\nNow, requests from the Docker container return with a 200 http status and everyone is happy ü§ó Hope this helps you if you are having a similar problem!\n\nAs a side note, while doing all this, I also needed to learn more about iptables and their different options. I found [this quick guide from **linode**](https://www.linode.com/docs/security/firewalls/control-network-traffic-with-iptables/) handy.\n\n**Thanks for reading me!**",["308","309","310"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"How to Find Ghost CSS Elements","CSS styles to help you find ghost or invisible spacing on your HTML","2018-05-11T16:14:30.939Z","how-to-find-ghost-css-elements-1h00","/david_ojeda/how-to-find-ghost-css-elements-1h00","https://dev.to/david_ojeda/how-to-find-ghost-css-elements-1h00","2018-05-11T16:14:30Z","---\ntitle: How to Find Ghost CSS Elements\npublished: true\ndescription: CSS styles to help you find ghost or invisible spacing on your HTML\ntags: CSS, HTML\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/6jddl1p3v9j2tl4ugjm6.png\ncanonical_url: https://dev.to/david_ojeda/how-to-find-ghost-css-elements-1h00\n---\n\nI recently came across a bug on our landing page which caused a weird blank space overflow on the right side:\n\n![Landing page with extra white space on right side][landing-page-bug]\n\nI looked for a couple of hours trying to find any CSS spacing causing it, or some wrong element on my HTML, but couldn't find anything out of place. The blank space wasn't even inside the &lt;html&gt; element of the page üßê\n\nI then [stumbled upon this post](http://wernull.com/2013/04/debug-ghost-css-elements-causing-unwanted-scrolling/) and rapidly found the problem. This blog post suggests some CSS styles to make ghost elements visible üëª:\n\n```css\n* {\n  background: #000 !important;\n  color: #0f0 !important;\n  outline: solid #f00 1px !important;\n}\n```\n\nNow, I could find the section that was causing the problem:\n\n![Landing page with ghost elements visible][landing-page-ghost]\n\nIn the end, it was a matter of fixing some mismatching HTML elements.\n\nWould've had this CSS styles helping me debug from the beginning, could've saved me a couple hours of work ü§¶üèª‚Äç‚ôÇÔ∏è\n\n\n[landing-page-bug]: https://thepracticaldev.s3.amazonaws.com/i/o1q1hlen9lqdy7dsc7zz.png \"Landing page with extra white space on right side\"\n\n[landing-page-ghost]: https://thepracticaldev.s3.amazonaws.com/i/909z7bing8w3g1u0ssmf.png \"Landing page with ghost elements visible\"\n","https://res.cloudinary.com/practicaldev/image/fetch/s--TM8JhiDk--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/6jddl1p3v9j2tl4ugjm6.png",["311","312"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"Extend nginx/Apache Proxy Configurations on AWS ElasticBeanstalk","Use .ebextensions feature of AWS ElasticBeanstalk to define custom configurations for your proxy server","2018-01-26T20:31:21.284Z","extend-nginxapache-proxy-configurations-on-aws-elasticbeanstalk-3mjg","/david_ojeda/extend-nginxapache-proxy-configurations-on-aws-elasticbeanstalk-3mjg","https://dev.to/david_ojeda/extend-nginxapache-proxy-configurations-on-aws-elasticbeanstalk-3mjg","2018-01-26T20:31:21Z","---\ntitle: Extend nginx/Apache Proxy Configurations on AWS ElasticBeanstalk\npublished: true\ndescription: Use .ebextensions feature of AWS ElasticBeanstalk to define custom configurations for your proxy server\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/8ndsgtt91bqudopf8m7o.png\ntags: aws, elasticbeanstalk, proxy\ncanonical_url: https://dev.to/david_ojeda/extend-nginxapache-proxy-configurations-on-aws-elasticbeanstalk-3mjg\n---\n\n<p>AWS ElasticBeanstalk applications use either an nginx or Apache proxy to relay requests. Using the .ebextensions feature of ElasticBeanstalk we can extend the configuration of these proxies. If you don't know how .ebextensions work you can read more <a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/ebextensions.html\">here.</a></p>\n\n<p>I'm going to extend the default nginx proxy configurations using .ebextensions. The same procedure can be used to extend an Apache proxy.</p>\n\n<h1>\n    Create a .conf file\n</h1>\n\n<p>First we need to create a .conf file with the desired directives. A list of nginx directives can be found <a href=\"http://nginx.org/en/docs/dirindex.html\"> here.</a> My conf file- named proxy.conf -increases some timeouts of the proxy:</p>\n\n{% gist https://gist.github.com/davidojedalopez/b3735a658fbd645b38a13405f9eae8fa %}\n\n<h1>Create nginx conf.d directory</h1>\n\n<p>Now we need the directory where our configuration file will be. Under .ebextensions, create a directory named 'nginx', and inside it another named 'conf.d'. Then add the file you just created. Your dir structure should look like this:</p>\n\n- .ebextensions\n    - nginx\n        - conf.d\n            - proxy.conf\n\nNow, when you deploy a new version of your application, ElasticBeanstalk will automatically copy your files on the `.ebextensions/nginx/conf.d/` directory to the `/etc/nginx/conf.d/` directory of your instances.\n\n<p>This all works because the default nginx.conf file- on line 21 -specifies to include all .conf files under the conf.d directory:</p>\n\n{% gist https://gist.github.com/davidojedalopez/680ae751eb2a3fd46c3bca04a33c5a4c %}\n\n<p>The directives from the .conf file will be added to the <em>http</em> block of the default configuration.</p>\n\n<p>If you need to add directives to the <em>server</em> block you will need to add .conf files to the elasticbeanstalk folder (see line 39 of previous Gist). That dir structure would look:</p>\n\n- .ebextensions\n    - nginx\n        - conf.d\n            - proxy.conf\n        - elasticbeanstalk\n            - my_other_conf.conf\n\n<p>Same can be done for an Apache proxy. The difference is on the directory structure. For Apache your structure should be this:</p>\n\n- .ebextensions\n    - httpd\n        - conf\n            - proxy.conf\n\n<h1>Wrap-up</h1>\n\n<p>Using .ebextensions is by far the simplest method to add custom configurations to your nginx or Apache proxy. Create as many configuration files as you need and add them to the corresponding directory under .ebextensions and you are done.</p>","https://res.cloudinary.com/practicaldev/image/fetch/s--m9Atdxe4--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/8ndsgtt91bqudopf8m7o.png",["277","279","313"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"Gated Commits with Git","Using Git hooks to run tests before each commit.","2017-09-25T13:20:57.464Z","gated-commits-with-git","/david_ojeda/gated-commits-with-git","https://dev.to/david_ojeda/gated-commits-with-git","2017-09-25T13:20:57Z","---\ntitle: Gated Commits with Git\npublished: true\ndescription: Using Git hooks to run tests before each commit.\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/k7kh73gxuasnrsig9wiu.png\ntags: git, ci\ncanonical_url: https://dev.to/david_ojeda/gated-commits-with-git\n---\n\n<p>A gated commit, also called a <strong>pre-tested</strong> commit, is an integration pattern in which a commit is not approved until a set of tests are ran against the code being commited. In other words, the commit does not go through if the test suite fails.</p>\n\n<p><strong>Why do you want this?</strong> It makes your application more resilient to change since now you are running a set or sub-set of your tests even before that code is available to anyone else.</p>\n\n<p>I am going to show you how to implement a gated commit pattern with Git. In this example, our <strong>unit test suite</strong> will be the <em>gate</em> to allow our commits to make it to the codebase.</p>\n\n___\n\n<h2>What do you need?</h2>\n\n<ul>\n    <li>Git</li>\n    <li>Your application's Git repo</li>\n    <li>A test suite</li>\n</ul>\n\n<h3>Starting off: Git Hooks</h3>\n\n<p>We want our tests to run before a commit goes through. Git allows us to run custom commands just before that event happens thanks to Git hooks. I am not going to go into the details on how they work, but conveniently for us, there is a hook called <strong>pre-commit</strong>. This hook is executed just before the commit happens. Perfect spot for our test suite to run.</p>\n\n<h3>Setting up a pre-commit hook</h3>\n\n<p>In your Git repo, there is a folder named .git in which the hooks are stored. If you have never modified any hook, your .git directory structure will look like this:</p>\n\n![.git directory structure](https://thepracticaldev.s3.amazonaws.com/i/ldij14knuw0xko7a2dcq.png)\n\n<p>To create our hook, we need to have a file called <strong>pre-commit</strong> (no extension required) inside our <strong>hooks</strong> directory. Let's create it. The only thing the file needs to have is the command you use to run your tests. Also, don't forget to make the file executable (chmod +x).</p>\n\n<p>If your application is, let's say, a Ruby application, you probably run your tests using <strong>rake</strong>. If that's the case, your <strong>pre-commit</strong> file will look like this:</p>\n\n<code>rake test:units</code>\n\n<br><br>\n\n<p>Or if you are into the JS hype, you can probably have this in your file:</p>\n\n<code>npm tests</code>\n\n<p>Independently of the language/framework you are using, your pre-commit hook needs to have the command to run your unit test suite. And, as long as the code inside the hook returns a <strong>zero exit code</strong>, the hook will allow the code to be commited. Otherwise, the commit will be rejected.</p>\n\n<h3>Testing</h3>\n\n<p>At this point you can go ahead and make a commit and see how our tests are run (and hopefully pass), thus opening the gate and letting the commit pass uncontested.</p>\n\n<p>In the following example I am using a Grails application, and the pre-commit hook contains the following code:</p>\n\n<code>grails test-app -unit</code>\n\n![Successful gated commit](https://thepracticaldev.s3.amazonaws.com/i/0oemd9h0kt5luq5ag79g.png)\n\n<h4>\n    <strong>Success!</strong> ü•≥\n</h4>\n\n<p>In the case that the test suite fails:</p>\n\n![Unsuccessful gated commit](https://thepracticaldev.s3.amazonaws.com/i/4g9jrtcxh85z1av658vq.png)\n\n<h4>Sad face üôÅ</h4>\n\n<h3>Wrapping up</h3>\n\n<p>We have just created a Git pre-commit hook that contains specific commands to execute our app's unit test suite. <strong>Whenever a commit is issued</strong>, our tests run. If tests pass, we have a successful commit, if not, commit is rejected.</p>\n\n<p>You can extend your tests of the pre-commit hook and build something <strong>as complex as you need</strong>. You can, for example, run a linter tool to make sure style guidelines are being followed. Or take it to the next level and integrate it with your Continuous Integration flow using additional hooks.</p>\n\n<p>Hope this helps you build more resilience into your codebase and, ultimately, deliver more value to your customers in a <strong>safe and rapid</strong> fashion!</p>","https://res.cloudinary.com/practicaldev/image/fetch/s--OL8tZY_T--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/k7kh73gxuasnrsig9wiu.png",["314","315"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"Hi, I'm David Ojeda","My introduction post","2017-07-13T02:17:35.138Z","hi-im-david-ojeda","/david_ojeda/hi-im-david-ojeda","https://dev.to/david_ojeda/hi-im-david-ojeda","2017-07-13T02:17:35Z","---\r\ntitle: Hi, I'm David Ojeda\r\npublished: true\r\ndescription: My introduction post\r\ntags: introductions\r\n---\r\n\r\nHello everyone! √∞≈∏‚Äì‚Äì√∞≈∏¬è¬º\r\n\r\n\r\nI have been coding for around 2.5 years now; 1.5 of those just learning and building really small stuff, the rest actually working as a software developer. \r\n\r\nYou can find me on Twitter as [@DavidOjedaL](https://twitter.com/DavidOjedaL). I usually post/retweet code related info, but lately have been getting into running too √∞≈∏¬è∆í√∞≈∏¬è¬Ω√∞≈∏‚Äô¬® \r\n\r\nI live in Guadalajara, M√É¬©xico √∞≈∏‚Ä°¬≤√∞≈∏‚Ä°¬Ω\r\n\r\nI work for Handy. We develop and maintain a sales workforce automation mobile and web application (also called Handy). We basically help companies sell more by providing visibility and control of sales operations, and tools for the sales people.  \r\n\r\nI mostly program in Groovy and JavaScript. Our web application is developed using Grails and we have a couple of microservices running on Nodejs. \r\n\r\nI am currently learning more about DevOps and Machine Learning.\r\n\r\nRecurrent reader of so much awesome content here on dev.to, and just decided to start writing some stuff myself!\r\n\r\nI am also a huuuuge fan of Overwatch, so if anyone's looking for some great matches, do talk to me √∞≈∏Àú‚Äπ\r\n\r\n\r\n\r\nNice to meet you all!",["316"],{"name":"268","username":"269","twitter_username":"270","github_username":"271","website_url":"272","profile_image":"273","profile_image_90":"274"},"showdev","writing","David Ojeda","david_ojeda","DavidOjedaL","davidojedalopez","https://davidojeda.dev","https://res.cloudinary.com/practicaldev/image/fetch/s--zT9WsPzg--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/18156/6e360d85-3ca0-41c4-a1e9-58fe52b10202.png","https://res.cloudinary.com/practicaldev/image/fetch/s--4_uVEPyC--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/18156/6e360d85-3ca0-41c4-a1e9-58fe52b10202.png","#091b47","#b2ffe1","aws","s3","elasticbeanstalk","discuss","#000000","#FFFFFF","stimulus","javascript","webdev","25daysofserverless","serverless","privacy","testing","help","#ff3232","#ffffff","groovy","grails","hibernate","Handy","handy","https://res.cloudinary.com/practicaldev/image/fetch/s--U5hLs1DG--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/organization/profile_image/377/c868a0c3-be56-4ec9-9c70-fd18320c784c.png","https://res.cloudinary.com/practicaldev/image/fetch/s--6nqXkHrt--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/organization/profile_image/377/c868a0c3-be56-4ec9-9c70-fd18320c784c.png","dev","domain","portfolio","outage","communication","beginners","tips","iam","docker","jenkins","iptables","css","html","proxy","git","ci","introductions"]